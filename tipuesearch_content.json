{"pages":[{"url":"http://www.7rack.info/pages/about-me.html","text":"最早和计算机认识应该是小时候的广告\"灯，等灯等灯！\":) 然后在《小学生导读》上读到\"千年虫\"，估计当时是没看懂哈哈+_+。 进入大学有了自己的电脑，从此就开始折腾了。 如今已工作（已离职，待业中），喜欢开源软件业余化、平民化。 从小喜欢听歌，喜欢计算机以及一切美好的事物。","tags":"pages","title":"About"},{"url":"http://www.7rack.info/Apache_log_parse_and_analysis.html","text":"Apache日志匹配 目前网站使用了 CDN、Nginx 和 Varnish 等缓存服务，因此在 Apache 的配置中，访问日志的格式如下： LogFormat \"%a %{X-Forwarded-For}i %l %u %t \\\"%r\\\" %>s %b %D \\\"%{Referer}i\\\" \\\"%{User-Agent}i\\\"\" combined 具体格式的意义可查看 Apache 的 文档 。实际记录数据如下： 192 .168.0.203 176 .34.13.244 , 153 .3.53.72 , 192 .168.0.202 - - [ 11 / Jul / 2014 : 00 : 00 : 37 + 0800 ] \"GET /post/3184410.html/30 HTTP/1.0\" 200 96145 104463 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/534.55.3 (KHTML, like Gecko) Version/5.1.5 Safari/534.55.3\" 在只需要统计与客户端 IP(176.34.13.244)相关的数据时，可先用 sed -e 's/[&#94; ]* \\([&#94;,]*\\),[&#94;-]*-/\\1 -/' 处理成 NCSA extended/combined log format 。 这样可以使用上很多通用的 Apache 日志处理软件或模块（如 Perl 的 Apache::LogRegex 和 Python 的 apachelog ）。 当然在 Python 中也可以手动写正则去匹配： re . compile ( r'''\\S+ #IP ADDRESS \\s+ #whitespace \\S+ #remoteaddr (,\\s+\\S+){0,2} \\s+ #whitespace - #remote logname \\s+ #whitespace \\S+ #remote user \\s+ #whitespace \\[(?P<date>[&#94;\\[\\]:]+):(?P<time>\\d+:\\d+:\\d+)\\s(?P<tz>\\S+)\\] #date & time \\s+ #whitespace \"\\w+\\s+(?P<uri>\\S+)[&#94;\"]+\" #first line of request \\s+ #whitespace ?P<status>\\d+) \\s+ #whitespace (-|\\d+) \\s* #whitespace ''' , re . VERBOSE ) 使用 pandas 分析 Apache 日志 这里使用 apachelog 模块去匹配日志。其他的模块 numpy、matplotlib、pandas 也需要更新下，这里以 Centos 6.5 为例： yum -y install python-devel freetype-devel libpng-devel easy_install pip pip install -U distribute numpy matplotlib pip install pandas xlwt 以下例子 来自 ： In [1]: % pylab inline Populating the interactive namespace from numpy and matplotlib 匹配日志，创建字典列表 In [2]: import apachelog , sys 设置格式 In [3]: fformat = r'%V %h %l %u %t \\\" %r \\\" %>s %b \\\" %i \\\" \\\"%{User-Agent}i\\\" %T' In [4]: p = apachelog . parser ( fformat ) In [5]: log = open ( 'access_log' ) . readlines () 匹配每一行，创建一个字典的列表 In [6]: log_list = [] for line in log : try : data = p . parse ( line ) except : sys . stderr . write ( \"Unable to parse %s \" % line ) #时间格式稍微转化下，便于 pandas 去匹配 data [ '%t' ] = data [ '%t' ][ 1 : 12 ] + ' ' + data [ '%t' ][ 13 : 21 ] log_list . append ( data ) 创建并调整Data Frame In [7]: import pandas as pd import numpy as np from pandas import Series , DataFrame , Panel In [8]: df = DataFrame ( log_list ) 删除一些暂时不需要的项 In [9]: del df [ '%T' ]; del df [ '%V' ]; del df [ ' %i ' ]; del df [ '%l' ]; del df [ ' %u ' ]; del df [ '%{User-Agent}i' ] 重命名 Data Frame 相关列 In [10]: df = df . rename ( columns = { '%>s' : 'Status' , '%b' : 'b' , '%h' : 'IP' , ' %r ' : 'Request' , '%t' : 'Time' }) 显示前5行 In [11]: df . head () Out[11]: Status b IP Request Time 0 200 26126 109.165.31.156 GET /index.php?option=com_content&task=section... 16/Mar/2013 08:00:25 1 200 10532 109.165.31.156 GET /templates/ja_procyon/css/template_css.css... 16/Mar/2013 08:00:25 2 200 1853 109.165.31.156 GET /templates/ja_procyon/switcher.js HTTP/1.0 16/Mar/2013 08:00:25 3 200 37153 109.165.31.156 GET /includes/js/overlib_mini.js HTTP/1.0 16/Mar/2013 08:00:25 4 200 3978 109.165.31.156 GET /modules/ja_transmenu/transmenuh.css HTTP/1.0 16/Mar/2013 08:00:25 将 Time 这一栏转换为 datatime 格式，并作为索引 In [12]: df . index = pd . to_datetime ( df . pop ( 'Time' )) In [13]: df [ 'Status' ] = df [ 'Status' ] . astype ( 'int' ) 将‘-'转化为 NaN，同时可根据需要将 bytes 换算为 Mb In [14]: def dash2nan ( x ): if x == '-' : x = np . nan else : x = float ( x ) / 1048576. return x In [15]: df [ 'b' ] = df [ 'b' ] . apply ( dash2nan ) 流量分析 首先简单绘出站点的流量 In [16]: df [ 'b' ] . plot () Out[16]: <matplotlib.axes.AxesSubplot at 0x10c0dd8d0> 统计一段时间间隔内的请求数和流量 In [17]: df_b = df [ 'b' ] . resample ( '10t' , how = [ 'count' , 'sum' ]) df_b [ 'count' ] . plot ( color = 'r' ) legend () df_b [ 'sum' ] . plot ( secondary_y = True ) Out[17]: <matplotlib.axes.Axes at 0x10c148f90> 状态码统计 根据 Status 分组 In [18]: grouped_status = df . groupby ( 'Status' ) In [19]: grouped_status . size () . plot ( kind = 'bar' ) Out[19]: <matplotlib.axes.AxesSubplot at 0x10c2f8490> 可查看每组的情况 In [20]: t_span = '30t' grouped_status . get_group ( 301 )[ 'Status' ] . resample ( t_span , how = 'count' ) . plot ( color = 'g' , label = '301' ) legend () grouped_status . get_group ( 200 )[ 'Status' ] . resample ( t_span , how = 'count' ) . plot ( color = 'b' , secondary_y = True , label = '200' ) Out[20]: <matplotlib.axes.Axes at 0x10c465690> IPs 可查看每个 ip 的请求数 In [21]: ips = df . groupby ( 'IP' ) . size () 仅查看前10 In [22]: ips . sort () ips [ - 10 :] . plot ( kind = 'barh' ) Out[22]: <matplotlib.axes.AxesSubplot at 0x10c327b90> 还可以同时根据 IP 和 Status 分组 In [23]: ips_status = df . groupby ([ 'IP' , 'Status' ]) . size () In [24]: ips_status . sort () ips_status [ - 20 :] . plot ( kind = 'barh' ) Out[24]: <matplotlib.axes.AxesSubplot at 0x10c4b34d0>","tags":"Linux","title":"Apache 日志匹配与分析"},{"url":"http://www.7rack.info/issues-of-June.html","text":"Cmd 常用命令减少资源消耗运行的方法： 移动大量文件到另一个目录 常用的方法是： find /foo -maxdepth 1 -atime +365 -exec mv {} /bar \\; 这样一次仅移动一个文件。 可使用 xargs 调用 subshell： find / foo - maxdepth 1 - atime + 366 - print0 | xargs - r0 sh - c ' mv \"$@\" / bar ' firstfile 此时 子shell ( -c )被 xargs 启动， $@ 部分使用双引号可以在文件名包含空格或换行能正确解析。 最后部分的 firstfile 作为子shell的 $0 。 打包压缩大量小文件 常用的方法是： find . -type f -print0| xargs -0 tar -czvf backup.tar.gz 这里会反复的去执行 tar -c 创建 backup.tar.gz 。 可以使用 tar 的 -T 选项： find . -type f -print0 | tar -czvf backup.tar.gz --null -T - MySQL主从 收到 Nagios 监控报警从库的同步出错，查看错误日志，发现 1032 错误： 140701 15 :00:07 [ ERROR ] Slave SQL : Could not execute Delete_rows event on table blog .posts ; Can 't find record in ' posts ', Error_code: 1032; handler error HA_ERR_KEY_NOT_FOUND; the event' s master log blog_0_122bin .000771 , end_log_pos 695930248 , Error_code : 1032 140701 15 :00:07 [ Warning ] Slave : Can 't find record in ' posts ' Error_code: 1032 140701 15:00:07 [ ERROR ] Error running query, slave SQL thread aborted. Fix the problem, and restart the slave SQL thread with \"SLAVE START\". We stopped at log ' blog_0_122bin .000771 ' position 695929475 出现这类错误是在基于行的复制(row-based replication, RBR)模式中，删除表中不存在的记录，会导致 SLAVE STOP。 最初设置的都是混合模式复制(mixed-based replication, MBR)。 MBR 模式中， 基于SQL语句的复制(statement-based replication, SBR) 模式是默认的。 但在几种 情况 下MIXED模式，会自动将binlog的模式由SBR模式改成RBR模式。 可手动跳过该语句 set global sql_slave_skip_counter = 1; 。 有时经常出现的错误，但不影响数据的完整性，可设置忽略 slave-skip-errors=1007,1008,1053,1062,1213,1158,1159 。","tags":"Linux","title":"问题集锦(六月)"},{"url":"http://www.7rack.info/npc-installation.html","text":"依赖 以下是至少需要的依赖： PHP 5.2( PDO 和 JSON 模块支持是必需的)。 最新的 NPC 版本 NDOUtils 1.4b7 Nagios 3.x Cacti 0.8.7b Cacti Plugin Architecture v2.0 PHP 注意修改php.ini文件中的 memory_limit 值，以足够运行 NPC。至少需要32 M： memory_limit = 32M 检查是否有PDO和JSON模块： [ root @7 rack ~ ] # php - m | grep - i ' pdo ' PDO pdo_mysql pdo_sqlite [ root @7 rack ~ ] # php - m | grep - i ' json ' json 安装NPC Cacti 必需安装了plugin architecture v2.0以上版本，才能安装 NPC。使用最新版Cacti已内建此功能。 Note：如果使用的 NPC 版本较低，可从 <path_to_cacti>/include/global.php 文件中移除 $ plugins [] = 'npc'; 自此，应该可以看到 NPC 这个标签，但是没有 NDO2DB 传输数据过来，所以没有任何信息。 同时也要在 Console 标签 -> Settings -> NPC 标签下设置 NPC。 配置Nagios 修改 nagios.cfg 文件中的以下参数。 允许传递命令给 Nagios 进程： check_external_commands=1 立即检查外部命令： command_check_interval=-1 代理所有事件 event_broker_options=-1 代理事件的配置文件，稍后需要安装。此处假设 Nagios 安装在 /usr/local/nagios ，同时注意如果 Nagios 版本情况，和ndoutils的安装方式，也可能会是ndomod-3x.o： broker_module=/usr/local/nagios/bin/ndomod.o config_file=/usr/local/nagios/etc/ndomod.cfg 如果你想通过 Nagios 插件的性能数据在 Cacti 上绘图： process_performance_data=1 安装配置 NDO2DB NDO2DB 是 NDOUTILS 包的一部分。 Nagios 通过事件代理处理 NDO2DB，NDO2DB 来处理将 Nagios 的数据插入 npc_ 表。 ndo2db 可通过 unix socket 或者 TCP 与 Nagios ndomod.o 连接。同时要在 ndo2db.cfg 和 ndomod.cfg 中设置一致。 推荐使用 TCP 的方式，最初我默认使用 unix socket ，出现如下错误： Jun 18 10:53:36 testhost nagios: ndomod: NDOMOD 1.5.2 (06-08-2012) Copyright (c) 2009 Nagios Core Development Team and Community Contributors Jun 18 10:53:36 testhost nagios: ndomod: Could not open data sink! I'll keep trying, but some output may get lost... Jun 18 10:53:36 testhost nagios: Event broker module '/usr/local/nagios/bin/ndomod.o' initialized successfully Jun 18 11:08:48 testhost nagios: ndomod: Still unable to connect to data sink. 16342 items lost, 5000 queued items to flush. 改为 TCP 连接方式，该错误消除。 但是又出现了如下错误： Jun 18 11:33:50 testhost ndo2db: Warning: Retrying message send. This can occur because you have too few messages allowed or too few total bytes allowed in message queues. You are currently using 64 of 16 messages and 65536 of 65536 bytes in the queue. See README for kernel tuning options. Jun 18 11:33:50 testhost ndo2db: Message sent to queue. Jun 18 11:33:50 testhost ndo2db: Warning: queue send error, retrying... 上述错误需要修改内核参数中的消息队列，查看默认的消息队列 # cat /proc/sys/kernel/msg{max,mni,mnb} 65536 16 65536 通过 echo 131072 > /proc/sys/kernel/msgmnb 暂时调节，以查看上述警告是否存在， 直到调整出合适大小。就可以加入到 /etc/sysctl 中，在系统重启后依然生效。 下面贴出 ndo2db.cfg 和 ndomod.cfg 配置： ndo2db.cfg ndo2db_user=nagios ndo2db_group=nagios socket_type=tcp socket_name=/usr/local/nagios/var/ndo.sock tcp_port=5668 db_servertype=mysql db_host=localhost db_port=3306 db_name=DATABSE_NAME db_user=DATABASE_USER db_pass=DATABASE_PASSWORD db_prefix=npc_ max_timedevents_age=1440 max_systemcommands_age=10080 max_servicechecks_age=10080 max_hostchecks_age=10080 max_eventhandlers_age=44640 debug_level=1 debug_verbosity=1 debug_file=/usr/local/nagios/var/ndo2db.debug max_debug_file_size=1000000 ndomod.cfg instance_name=default output_type=tcpsocket output=127.0.0.1 tcp_port=5668 output_buffer_items=5000 buffer_file=/usr/local/nagios/var/ndomod.tmp file_rotation_interval=14400 file_rotation_timeout=60 reconnect_interval=15 reconnect_warning_interval=15 data_processing_options=-1 config_output_options=2 调整npc_数据表 使用时会发现 Nagios 中 /var/log/messages 中在插入数据时有错误， 因此需要调整几个数据表： alter table npc_eventhandlers add long_output TEXT NOT NULL default '' after output; alter table npc_hostchecks add long_output TEXT NOT NULL default '' after output; alter table npc_hoststatus add long_output TEXT NOT NULL default '' after output; alter table npc_notifications add long_output TEXT NOT NULL default '' after output; alter table npc_servicechecks add long_output TEXT NOT NULL default '' after output; alter table npc_servicestatus add long_output TEXT NOT NULL default '' after output; alter table npc_statehistory add long_output TEXT NOT NULL default '' after output; alter table npc_systemcommands add long_output TEXT NOT NULL default '' after output; 可用如下命令查询，数据是否成功写入npc_表中： select host_id,alias,address from npc_hosts; 如果在 NPC 标签中 Nagios 显示 OFF，则说明 npc_programstatus 表中没有 status_update_time ，或者时间离现在很久： mysql> select programstatus_id,instance_id,status_update_time,last_command_check,last_log_rotation from npc_programstatus; +------------------+-------------+---------------------+---------------------+---------------------+ | programstatus_id | instance_id | status_update_time | last_command_check | last_log_rotation | +------------------+-------------+---------------------+---------------------+---------------------+ | 5 | 1 | 2014-06-20 00:09:00 | 2014-06-20 00:09:00 | 2014-06-20 00:00:00 | +------------------+-------------+---------------------+---------------------+---------------------+ 1 row in set (0.00 sec) Note 如果 ndo2db 进程经常自动结束，可将它加入 init 中，自动检测重启： ndo : 345 : respawn :/ usr /local/nagios/bin/ndo2db -c /usr/local/nagios/etc/ ndo2db . cfg 如果出现 Nagios 无法正常停止或重启，可在 /etc/init.d/nagios 加入如下内容： ## BEGIN INIT INFO # Provides: nagios # Required-Start: ndo2db # Required-Stop: ndo2db # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: start and stop Nagios monitoring server # Description: Nagios is is a service monitoring system ### END INIT INFO","tags":"Monitoring","title":"NPC安装"},{"url":"http://www.7rack.info/linux-performance-analysis-and-tools.html","text":"背景 为什么要做系统性能分析？ 减少成本 ：找到并减少资源浪费，调整策略，用较少的资源做更多的事 构建可伸缩架构 ：理解系统的限制和可扩展性 解决问题 ：找到瓶颈和延迟异常值 你需要知道一些系统知识 Operating System +------------------------------------------------------+ | Applications | | +-----------------------------------------+ | | System Libraries | user-level +------------+-----------------------------------------+ &#94; | System Call Interface |XXXXXXXXXXXXXXXXXXXX | +--------------------------+--------------+------------+ | | VFS | Sockets | | kernel-level | | | | | | +---------------+-------------------------+ Scheduler| | | | | | | | | ext3/... | | TCP/UDP | | Linux | | | ZFS | | | Kernel | +---------------+ +---------------------------+ | | | | | | | | LVM | | IP | | | | | | | Virtual | | +---------------++------------------------+ Memory | | | Block Device Int. | Ethernet | | | | | | | v +--------------------------+--------------+------------+ | DEVICE DRIVERS | +------------------------------------------------------+ 即使你打算使用监控产品，学习研究常见的系统指标（如 iostat，...）是值得的。 监控产品通常也是使用相同的指标，从 /proc 读取。 Analysis and Tools 快速的浏览下工具，看看能做什么。 图片来自 linux-performance-analysis-and-tools Basic uptime 显示的 load averages ，其他工具同样可以显示： # uptime 17:03:42 up 14 days, 20:33, 1 user, load average: 1.08, 0.42, 0.19 代表的是 1, 5, 15 分钟，系统平均要负责运行几个线程(任务)的意思。 通过这些值，可以看出负载是增加，稳定还是下降。 若负载大于 CPU 个数，这可能意味着 CPUs 使用达到饱和，线程调度延迟，也可能是磁盘 I/O 因素。 这只能作为一个线索，接着用其他工具调查。 top 系统范围每个进程的概要 # top top - 18:25:02 up 14 days, 21:55, 1 user, load average: 0.00, 0.03, 0.05 Tasks: 133 total, 1 running, 132 sleeping, 0 stopped, 0 zombie Cpu ( s ) : 6.7%us, 4.4%sy, 0.0%ni, 84.6%id, 4.4%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 2046584k total, 1862660k used, 183924k free, 61804k buffers Swap: 4128760k total, 1522144k used, 2606616k free, 87132k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 55914 zenoss 20 0 874m 128m 3584 S 1.7 6.4 16:08.78 runzope 46351 mysql 20 0 1016m 105m 4140 S 1.0 5.3 87:48.43 mysqld 16 root 20 0 0 0 0 S 0.7 0.0 244:47.86 kblockd/0 [ ... ] 每个Process对应： PID： process 的 ID USER：所属的使用者 PR ：Priority 的简写，程序的优先运行顺序，越小越早被运行 NI ：Nice 的简写，与 Priority 有关，也是越小越早被运行 %CPU：CPU 的使用率 %MEM：内存的使用率 TIME+：CPU 使用时间的累加 top 可能错过 short-lived 进程。 %CPU 高也可能是因为内存I/O，升级更快的 CPU 并没有帮助。 htop 是用于取代 Linux 下的 top ，功能比 top 强。 htop 提供更方便、光标控制的界面来杀死进程。 mpstat 检查紧迫的进程，负载不均衡： # mpstat -P ALL 1 09:19:38 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %idle 09:19:39 PM all 1.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 98.00 09:19:39 PM 0 1.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 98.00 mpstat 是 Multiprocessor Statistic 的缩写，是实时的系统监视工具。 报告与 CPU 的一些统计信息，可显示各个可用 CPU的状态。 这些信息存放在 /proc/stat 文件中。 iostat 显示磁盘 I/O 统计，第一行显示的是自系统引导以来的数据汇总。 # iostat -xkdz 1 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 2.57 210.34 10.74 136.67 63.21 1388.06 19.69 0.46 3.11 0.83 12.22 dm-0 0.00 0.00 11.25 345.44 54.91 1381.75 8.06 1.41 3.95 0.34 12.12 dm-1 0.00 0.00 2.07 1.58 8.29 6.31 8.00 0.04 10.41 0.73 0.27 Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await svctm %util sda 0.00 18.56 1.03 10.31 8.25 115.46 21.82 0.05 4.00 4.00 4.54 dm-0 0.00 0.00 0.00 28.87 0.00 115.46 8.00 0.03 1.04 1.04 2.99 前面几列是输入工作负载，后面5列显示性能。 avgrq-sz ：每次请求的扇区平均数。 avgqu-sz ：监测时间间隔内平均队列长度 await ：每个 IO 请求到完成的平均时间。值为 queuetime + svctim svctm ：监测时间间隔内每个 IO 请求完成的平均时间 %util ：描述设备在服务于请求的时间百分比，值为 (r/s + w/s)*svctm/1000*100 %util ：有效性取决于目标，多块磁盘组成的虚拟设备，可达到100%的利用率。 详细的分析可参看 iostat and disk utilization monitoring nirvana 或者 man。 vmstat 显示虚拟内存统计数据，以及其它高级摘要： # vmstat 1 procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 1520376 76000 157972 146784 8 6 62 1370 26 9 4 6 83 8 0 0 0 1520376 75992 157972 146812 0 0 0 0 163 291 2 1 97 0 0 0 0 1520376 75744 157972 146816 0 0 0 116 200 372 2 0 98 0 0 同样的第一行也显示自系统引导以来的数据。 r = 可运行的线程总数，也包括正在运行的。 如果该值一直大于系统中 CPU 个数，表示系统运行过慢。 内存置换空间（swap）这列中： so 表示内存不足而将没用到的程序写入到 swap 的容量， 丢失了性能。 free 内存使用情况（默认 Kbytes） # free total used free shared buffers cached Mem: 2046584 1975648 70936 0 158240 148548 -/+ buffers/cache: 1668860 377724 Swap: 4128760 1520372 2608388 buffers：块设备的 I/O 缓存 cached：虚拟页面缓存 nicstat 网络流量统计工具 # nicstat -z 1 Time Int rKB/s wKB/s rPk/s wPk/s rAvs wAvs %Util Sat 15:30:44 lo 4.01 4.01 13.96 13.96 294.5 294.5 0.00 0.00 15:30:44 eth3 22.86 6.48 25.05 8.04 934.6 825.1 0.02 0.00 Time Int rKB/s wKB/s rPk/s wPk/s rAvs wAvs %Util Sat 15:30:45 lo 4.03 4.03 9.98 9.98 413.1 413.1 0.00 0.00 15:30:45 eth3 1.25 0.57 14.97 3.99 85.33 146.0 0.00 0.00 可关注下 %Util 网卡利用率 Sat 网卡每秒的错误数 dstat 一个全能的系统信息统计工具，比 vmstat 更好。 图片来自 linux-performance-analysis-and-tools Intermediate sar System Activity Reporter，例如报告分页数据 -B ： $ sar -B 3 Linux 3.11.0-20-generic ( precise ) 2014年05月16日 _x86_64_ ( 4 CPU ) 22时08分28秒 pgpgin/s pgpgout/s fault/s majflt/s pgfree/s pgscank/s pgscand/s pgsteal/s %vmeff 22时08分31秒 0.00 0.00 13.67 0.00 21.00 0.00 0.00 0.00 0.00 22时08分34秒 0.00 0.00 8.00 0.00 14.67 0.00 0.00 0.00 0.00 22时08分37秒 0.00 0.00 13.67 0.00 27.67 0.00 0.00 0.00 0.00 还有其他选项： -d ：block device statistics -q : run queue statistics 和其他工具（vmstat、iostat）显示的数据一样。 netstat 显示所有协议的数据使用 -s ： $ netstat -s [ ... ] Tcp: 127116 active connections openings 165223 passive connection openings 12904 failed connection attempts 19873 connection resets received 20 connections established 662889209 segments received 354923419 segments send out 405146 segments retransmited 6 bad segments received. 26379 resets sent [ ... ] TcpExt: 2142 invalid SYN cookies received 3350 resets received for embryonic SYN_RECV sockets 7460 packets pruned from receive queue because of socket buffer overrun 2932 ICMP packets dropped because they were out-of-window 96670 TCP sockets finished time wait in fast timer 86 time wait sockets recycled by time stamp 1007 packets rejects in established connections because of timestamp [ ...many... ] pidstat 非常有用的进程分析： pidstat -d 1 Linux 2.6.32-431.11.2.el6.x86_64 ( l-test-xiangw-1 ) 05/16/2014 _x86_64_ ( 1 CPU ) 10:28:55 PM PID kB_rd/s kB_wr/s kB_ccwr/s Command 10:28:56 PM 1756 0.00 3.92 0.00 beam 10:28:56 PM 4193 0.00 39.22 0.00 nagios 10:28:56 PM 46351 0.00 3.92 0.00 mysqld 10:28:56 PM 55992 0.00 35.29 0.00 python 以上显示的 disk I/O strace 系统调用 tracer： strace -ttT -p 55914 Process 55914 attached - interrupt to quit 22:44:10.802649 select ( 11, [ 3 10 ] , [] , [ 3 10 ] , { 20, 286066 }) = 1 ( in [ 3 ] , left { 12, 587286 }) <7.698874> 22:44:18.501858 accept ( 3, { sa_family = AF_INET, sin_port = htons ( 19980 ) , sin_addr = inet_addr ( \"10.49.4.229\" )} , [ 16 ]) = 25 <0.000022> 22:44:18.502063 fcntl ( 25, F_GETFL ) = 0x2 ( flags O_RDWR ) <0.000011> -tt ：记录每个系统调用发生时的时间 -T ：记录每个系统调用花费的时间（seconds） -p ：跟踪某个后台进程 Useful：I/O 资源导致应用的高延迟，系统调用占用多数 I/O 资源。 -c ：摘要 # strace -c dd if=/dev/zero of=/dev/null bs=512 count=1024k [ ... ] % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 55.35 1.473574 1 1048579 write 44.35 1.180639 1 1048581 read [ ... ] tcpdump 嗅探网络数据包，转储为文件以便分析： # tcpdump -i eth0 -w /tmp/out.tcpdump tcpdump: listening on eth0, link-type EN10MB ( Ethernet ) , capture size 65535 bytes &#94;C581 packets captured 581 packets received by filter 0 packets dropped by kernel # tcpdump -nr /tmp/out.tcpdump [ ... ] 可以研究奇怪的包转发延迟 也可将抓包文件导入其他工具（wireshark） blktrace 块设备 I/O 事件跟踪。 # btrace /dev/mapper/vg_cloud-lv_root 253,0 0 1 0.000000000 413 Q WS 4661960 + 8 [ jbd2/dm-0-8 ] 253,0 0 2 0.000030599 413 Q WS 4661968 + 8 [ jbd2/dm-0-8 ] 253,0 0 3 0.000042099 413 U N [ jbd2/dm-0-8 ] 0 [ ... ] 显示了磁盘的 I/O 事件，可用于调查 I/O 延迟异常值。 iotop 进程的磁盘 I/O： # iotop -bod5 Total DISK READ: 35.38 M/s | Total DISK WRITE: 39.50 K/s TID PRIO USER DISK READ DISK WRITE SWAPIN IO COMMAND 12824 be/4 root 35.35 M/s 0.00 B/s 0.00 % 80.59 % cksum ... 279 be/3 root 0.00 B/s 27.65 K/s 0.00 % 2.21 % [ jbd2/vda2-8 ] 12716 be/4 root 28.44 K/s 0.00 B/s 2.35 % 0.00 % sshd: root@pts/0 12816 be/4 root 6.32 K/s 0.00 B/s 0.89 % 0.00 % python /usr/bin/iotop -bod5 [ ... ] IO：等待 I/O 的时间线索（这个甚至比 pidstat's Kbytes更有用） 需要 CONFIG_TASK_IO_ACCOUNTING 或者启用类似的配置。 slabtop 实时的显示内核 slab 缓冲区的细节信息 # slabtop -sc Active / Total Objects ( % used ) : 305162 / 397268 ( 76.8% ) Active / Total Slabs ( % used ) : 20831 / 20832 ( 100.0% ) Active / Total Caches ( % used ) : 102 / 182 ( 56.0% ) Active / Total Size ( % used ) : 75354.86K / 85579.39K ( 88.1% ) Minimum / Average / Maximum Object : 0.02K / 0.21K / 4096.00K OBJS ACTIVE USE OBJ SIZE SLABS OBJ/SLAB CACHE SIZE NAME 19880 19795 99% 0.99K 4970 4 19880K ext4_inode_cache 81820 81740 99% 0.19K 4091 20 16364K dentry 117068 55630 47% 0.10K 3164 37 12656K buffer_head 181 181 100% 32.12K 181 1 11584K kmem_cache 16576 14031 84% 0.55K 2368 7 9472K radix_tree_node 19722 19300 97% 0.20K 1038 19 4152K vm_area_struct [ ... ] 显示内核内存的消耗。 sysctl # sysctl -a [ ... ] net.ipv4.route.redirect_number = 9 net.ipv4.route.redirect_silence = 20480 net.ipv4.route.error_cost = 1000 net.ipv4.route.error_burst = 5000 net.ipv4.route.gc_elasticity = 8 net.ipv4.route.mtu_expires = 600 net.ipv4.route.min_pmtu = 552 [ ... ] 静态性能调优：检查系统配置。 主要参看 linux-performance-analysis-and-tools 。","tags":"Linux","title":"Linux 性能分析及工具"},{"url":"http://www.7rack.info/5-Unsung-tools-of-devops.html","text":"翻译自 《5 Unsung Tools of DevOps》 ，可在 oreilly 网站免费下载该电子书。 工具对提高工作效率起着至关重要的作用。 在技术世界不断变化的今天，我们倾向于关注最新的和最好的解决方案，而忽视可用的简单工具。 不断改进的工具是 DevOps 发展的一个重要方面，但进步并不意味着替代。 这里有我几乎每天都用的5个工具。 它们提供对环境的监控和控制，然而只需最小化安装和配置。 它们不是什么浮华的工具，但它们经过了时间的考验，且有效的工作。 It has long been an axiom of mine that the little things are infinitely the most important. --Sir Arthur Conan Doyle RANCID 像 Puppet 和 Chef 的配置管理（CM）工具能保持对系统进行有效的控制，但是你的基础设施怎么办？ Really Awesome New Cisco confIg Differ （RANCID）是解决这个问题的第一步。本质上， RANCID 是一套自动在版本控制系统中保留你的配置。如果你有在任何级别的物理基础架构，你应该像服务器的 CM 解决方案一样管理它。 这听起来不错，但是 RANCID 能解决什么实际问题呢？ 核心应用是为那些粘合服务器到一起的设备创建一条软件配置和硬件信息的审查轨迹。 你的交换机、路由器和负载均衡器的配置也许不会像你 Rails 应用中的代码频繁修改，但随着时间的过去确实会改变。 改变的速率经常与你的环境是否改变或者扩展有关。 审核（Auditing）是自动化过程中伟大的第一步。 你必须清楚你去哪里得到和究竟去向哪里。 RANCID 对 Cisco 、Juniper 、F5 和其它厂家的设备是立即可用的。 审计进程需要 RANCID 的基本安装和在想要的监控设备上配置一个只读用户。 当前的配置就会定期自动地拉取并提交到版本控制系统中，发送一封详细的配置变更邮件。 所以现在你已经准备试试 RANCID ，但从何而起呢？ 如果你的是 Subversion ，你可以抓取 the latest tarball ,然后按照 Getting Started 的指引。 Git 用户可以抓取 RANCID 带 patched to add git functionality 的fork。 虽然 git 不是被 RANCID 的维护者原生支持，我更喜欢 git ，所以选用上面的fork。 一旦你安装了 RANCID，在 /etc/rancid/rancid.conf （或者其它的安装位置）有几处基本的配置项需要设置。 rancid.conf RCSSYS=git FILTER_PWDS=YES LIST_OF_GROUPS=\"pdx slc ord\" 配置 RANCID 去拉取配置需要用户名和密码以连接每个设备，根据需要使用 hostname 匹配。 RANCID 支持通过 telnet 和 ssh 来连接设备。 我相信不用多说，不要使用 telnet ，甚至在设备上启用它！ 有些设备支持 key-based 授权（像 Juniper 和 F5）同时无需密码。 既然这样，RANCID 将用 rancid 用户下的 ssh key （如果已经配置），同时配置 RANCID 通过ssh连接。 否则你需在 .cloginrc 文件中配置密码，该文件在 rancid 用户目录下。这里是一个例子： ~/.cloginrc # We only use SSH add method * {ssh} # Wildcard for all devices add password *.example.com LoginPassword EnablePassword add password router.example.com OtherPass AndAnotherPass 最后你需要配置设备属于哪个 group 。 你需为每个组创建一个目录，目录名和组名相同，且每个都包含一个配置文件。 RANCID 在此显示它的一些继承物，如同此配置文件叫 router.db 。这不限于路由器，不过这也不是数据库而是一个简单文本文件。 文件中的每一行以 hostname:type:status 代表一个设备,其中 type 是支持的设备列表中的设备类型， status 是 up 后者 down 。 被标记为 down 的设备不会询问其配置，但会一致保存在版本控制系统中。这里是一个例子： ~/pdx/router.db switch.example.com:cisco:up router.example.com:juniper:up balance.example.com:f5:up 现在，假如你已经在上面的设备配置了 RANCID 用户，作为 RANCID 用户，你可以手动运行 rancid-run 来收集所有的配置。 一旦设备被查询，所有的配置将存放在 ~/pdx/configs/switch.example.com ，而且一个 diff 将被 email 到 rancid-pdx ，这与你之前的别名一致。 唷（?_?）现在你可以在运行 RANCID 系统中安全轻松的知道所有已设置设备的配置和硬件信息。 这也许已经足够，但有本地的 git 仓库去提交或许更好。这里有简单的设置。 Set up a remote for the git repo $ git remote add upstream <git url> Create the following file at ~/.git/hooks/post-commit #!/bin/sh # Push the local repo to my upstream on commit git push upstream 现在你已经详细的了解设置 RANCID ，而且去跟踪你的配置，去hack it吧！ 带着控制设备的目标，你可以扩展当前的 CM 解决方案以达到网络机架的深度。 更详细的信息，去检查http://www.shrubbery.net/rancid/网站，并看看Shrubbery Networks公司其他可用的工具。 Cacti 我想 Cacti 是 Graphite 的鼻祖。 它是基于 round robin 数据库的统计画图工具，以使用 SNMP（Simple Network Management Protocol）的网络设备为目标，你可在 http://www.cacti.net/ 找到。 它并不流行也不写在节点上，那为什么要考虑它呢？ Cacti 是很适合当你需要轮询设备以收集信息，而不是设备上报数据。配置集中在运行的服务器上，更多的是 it Just Works 。 Cacti 提供 Web UI，这样你可以快速上手，包含了 user、device 和 graph management。 后端，Cacti 作用 RRDTool 去存储已设置设备的时间序列数据。 RRD 可以方便的存储设定时间段的数据，文件也不会增大。 Cacti 通过存储数据到多重 round robin 档案（RRAs）来处理长时间数据保存。 RRAs 定义了越过指定长时间（Timespan）存储多少个数据点（Rows），同时如何聚合数据点（Steps）。 Steps 是此 RRA 一个数据点对数据点个数的平均指数。 当然你也可以调整默认值像创建自己的 RRAs ,如18 months、2 years 或者其他你想要的 timespan。 这里值得注意的重要项是 Steps 和 Rows 。step 的尺寸定义了在RRA中多少条数据点合并为一个数据点。 Timespan 定义了从数据源每多少秒画一次图。 Cacti 一个最大的优点是基于模版的配置，允许很赞的定制。 开始有各种设备的模版叫 Host Templates 。Host Template 定义了与某种设备关联的 Graph Templates。 例如有一个内建的 Cisco Router Host Template，你分配这个模版给某个设备，Cacti 知道哪些图形模板是相关的。 这相比你必须整理整个图形模版列表有压倒性优势！ 那么 Cacti 是如何知道你的交换机有多少端口呢？答案很简单，Cacti 使用 SNMP 或者其他自定义 Data Query 询问设备。 SNMP 越来越老，但它仍是获得结构化数据简单快捷的方法，这正是 Data Queries 发挥作用。 像Data Query 中 SNMP - Interface Statistics ，有结果的索引值并以此遍历结果和收集相关信息。 如果你有数据不适合通过 SNMP，Cacti 支持在服务器上运行自定义脚本来收集任何需要的信息。 通过一个询问很多问题的简单 web 表单来完成配置一个新设备，但它可以归结为 Description 、 Hostname 和 Host Template 。 大多数其他设置可以继承系统默认值，比如 timeouts 和 SNMP 连接详细。 当在远程主机上配置 SNMP 时，务必要改变 community ，而不是使用默认的\"public\"。 另外强烈推荐限制可以查询 SNMP 数据的主机甚至限制这些主机可以查看的数据。 一旦你完成创建主机，将会被重定向到主机详细同时可以选择创建图形。单击链接到与设备相关 Graph Templates 列表。 简单的勾选你想创建的图形旁边的复选框，然后点击 Create。 在接下来的5分钟（默认的轮询间隔），你应该开始看到刚为设备添加的图形数据。 这里有个低利用率交换机端口的 Hourly 图形例子。 由于默认的轮询周期是5分钟（也许在今天的标准有点长），会出现阶梯。 绿色区域代表传入流量，蓝色线条代表出站。这个图形模版也包括其95%（没有显示在图上）作为常见的网络流量计费方式。 你可以轻易的查看特定主机的图形，但这不是查看数据最有效的方法。 Cacti 的另一个特点是 Graph Trees。 Graph Trees 允许你创建类似文件夹的结构去排列和查看图形。 想一次性查看所有树莓派的网络吞吐量？没问题！ 我们在 Default Tree 下创建 Header 类型的 Switch，并只包含我们关心的图形： 在 Cacti 下从 Console 标签移到 Graph 视图，查看刚刚的成果。 这两种模式把配置和常规使用区分开来，并稍微改变界面。 不用担心，这就像点击一个页面上的标签来回切换。 这是 Cacti 的 Graphs 视图，左侧包含 Graph Tree ，顶部有快速过滤器，图形结果在主体部分显示。 这里也显示了 Cacti 有些年头了。 虽然页面主要是动态内容，但没有使用 AjAX，所以页面是通过 meta 标签刷新， 而且在与图形直接交互时，你不能改变时间范围查看。 如果你足够关注，会注意到上图是 Hourly RRA 中最近一个小时的数据。 如果你想查看特定图形的所有时间阶段，只用点击它，将会进入该数据的整个存储历史中。 这对识别随着时间推移的趋势非常有用，能让你规划未来的发展。 lldpd 链路层发现协议（LLDP）是一个你可能从未听过，未充分使用而非常有用的网络协议。 曾经因为过时的文档或者乱麻样的布线，而拔错服务器网线？是的，我干过... 但现在你可以自信确切的知道服务器插入的端口！ 你只需要在交换机上启用 LLDP，同时安装 lldpd。 我们应该注意到，多年来多个网络设备供应商实现了其他的链路层协议。 LLDP 是以 IEEE 802.1AB 标准定义的厂商中立的规范。 现在不同厂商设备间终于可以交换信息，这重要的一步，让网络工程师们兴奋。 现在是时候将这个消息呈现给广大受众。 虽然 LLDP 的内部工作机理远远超出了本文的范围，基本使用还是很简单。 一个设备可以是服务器、交换机、路由器或者其他设备，每隔一定时间向所有已连接网络接口发送信息。 这些信息通常包含系统名称、发送数据接口的名称和管理地址 IP。 然后接受设备收集数据，添加数据传入的接口，并将其存储一定的时间。 数据交换只发生在以太网直连设备间，所以你可以确定特定接口上的邻居。 Capability Codes: R - Router, T - Trans Bridge, S - Switch, H - Host, I - IGMP, r - Repeater Device ID Local Intrfce Capability Platform Port ID rpi-1 Fas 0/2 H Linux eth0 rpi-2 Fas 0/1 H Linux eth0 这是个老式 Cisco 交换机的例子，连接有2个 Linux 主机。 如果需要断开 rpi-1 设备的 eth0 口，就知道是插在交换机的 FastEthernet 0/2 端口。 我还可以分辨出 rpi-2 不是交换机，因为在 Capability 列标记为 H ，表示是主机。 在 Linux 下有 LLDP 少数的实现： Open-LLDP 、 ladvd 和 lldpd 。 我更喜欢 lldpd 的配置简单，它也可以和其他像 Cisco Discovery Protocol 专有发现协议对话，客户端工具有多种输出格式。 取决于你正在使用的 Linux 发行版，也许没有可用的 lldpd 软件包，但遵从标准的编译安装模式。 软件包安装完成后，确实不用过多的配置。 例如使用 Rasbian 包安装，你只需运行守护进程。 使用 CDP（Cisco Discovery Protocol）需要稍加改动配置，如下： /etc/defaults/lldpd # Start SNMP subagent and enable CDP DAEMON_ARGS=\"-x -c\" 一旦 lldpd 安装完成并运行，只需几秒钟从临近设备传入数据。 使用 lldpctl 命令查看当前 LLDP 信息，默认将打印出一些详细信息。 在下面的例子中，你可以看到实际在采用 CDP 和老的 Cisco 2924 交换机通讯： ----------------------------------------------------------- LLDP neighbors: ----------------------------------------------------------- Interface: eth0, via: CDPv2, RID: 4, Time: 8 days, 00:58:39 Chassis: ChassisID: local switch.example.com SysName: switch.example.com SysDescr: cisco WS-C2924-XL MgmtIP: 192.168.1.2 Capability: Bridge, on Port: PortID: ifname FastEthernet0/2 PortDescr: FastEthernet0/2 VLAN: 1, pvid: yes VLAN #1 到目前为止这是人们可以解析的所有可用信息，但这不是我想致力于的规模。 lldpctl 帮了我们大忙，提供 key-value 和 XML 多种输出格式。 这里有个同样的 key-value 的输出格式来对照： $ lldpctl -f keyvalue lldp.eth0.via = CDPv2 lldp.eth0.rid = 4 lldp.eth0.age = 8 days, 01:00:23 lldp.eth0.chassis.local = switch.example.com lldp.eth0.chassis.name = switch.example.com lldp.eth0.chassis.descr = cisco WS-C2924-XL lldp.eth0.chassis.mgmt-ip = 192.168.1.2 lldp.eth0.chassis.Bridge.enabled = on lldp.eth0.port.ifname = FastEthernet0/2 lldp.eth0.port.descr = FastEthernet0/2 lldp.eth0.vlan.vlan-id = 1 lldp.eth0.vlan.pvid = yes lldp.eth0.vlan = VLAN #1 现在有了服务器是如何连接到世界其他角落的信息，且是易于分析的格式，稍微加工可以传递给配置管理软件。 这变得很重要的原因之一是它允许自动发现服务器和直连网络设备之间的父子关系。 通过简单的包装（假如你是 Puppet 用户），获得所连接交换机（父节点） hostname。 现在当动态生成你的监控配置，就可以传递你已连接到 Switch.example.com 的信息。 IPerf 比特随着不断变化的不对称路径从一个地方移到另一个地方，网络有时是一个奇怪的地方。 有时这将导致服务器之间非常不同的吞吐量性能，否则似乎是相同的。 在运行一些常见工具像 traceroute 或者 curl ，你任然无法重现问题。 使用 Iperf 吧，一个网络测试工具。 Iperf 被设计以客户端/服务端的方式运行，测量两点间的吞吐量。 它同时支持 UDP 和 TCP，可以在每个端点用一个命令进行双向或单向测试。 Iperf 的威力在于非常有效的使网络连接饱和。对于 TCP，它报告整体的吞吐量。 对于 UDP ，你可以调整数据包大小，同时报告中包括吞吐量、丢包、抖动。 安装简单，在主流的 Linux 发行版中已经有安装包，同时支持跨平台编译，Windows 下也有第三方提供的二进制文件。 为运行 iperf，你需要配置防火墙允许2个端点之间的连接，默认的 TCP 和 UDP 服务端口是5001。 同时需要在连接的两端运行 iperf 来测试，iperf 可以运行在服务端或客户端模式下，如下面的例子： TCP Server Mode $ iperf -s ----------------------------------------------------------- Server listening on TCP port 5001 TCP window size: 85.3 KByte ( default ) ----------------------------------------------------------- [ 4 ] local 192.168.1.101 port 5001 connected with 192.168.1.100 port 43697 [ ID ] Interval Transfer Bandwidth [ 4 ] 0.0-10.1 sec 114 MBytes 94.1 Mbits/sec TCP Client Mode $ iperf -c 192.168.1.101 ----------------------------------------------------------- Client connecting to 192.168.1.101, TCP port 5001 TCP window size: 22.9 KByte ( default ) ----------------------------------------------------------- [ 3 ] local 192.168.1.100 port 43697 connected with 192.168.1.101 port 5001 [ ID ] Interval Transfer Bandwidth [ 3 ] 0.0-10.0 sec 114 MBytes 95.0 Mbits/sec 用 iperf 执行一个初始的 TCP 测试需运行服务，然后在客户端连接它。 在上面的例子中，树莓派作为服务端运行，同时另一个系统向它发送流量。 最终的结果是衡量从客户端到服务端完整的吞吐量。 你可以用 -r 标志每次运行一个来进行双向测试，或者传递 -d 标志到客户端同时进行双向测试。 选用哪种方法取决于你预期的工作负载，但通常当系统运行在相同的硬件上，独立测试的统计结果应该类似。 UDP Server Mod $ iperf -s -u ----------------------------------------------------------- Server listening on UDP port 5001 Receiving 1470 byte datagrams UDP buffer size: 160 KByte ( default ) ----------------------------------------------------------- [ 3 ] local 192.168.1.101 port 5001 connected with 192.168.1.100 port 55272 [ ID ] Interval Transfer Bandwidth Jitter Lost/Total [ 3 ] 0.0-10.0 sec 114 MB 95.7 Mbps 0.158 ms 0/81482 [ 3 ] 0.0-10.0 sec 1 datagrams received out-of-order UDP Client Mode $ iperf -u -c 192.168.1.101 ----------------------------------------------------------- Client connecting to 192.168.1.101, UDP port 5001 Sending 1470 byte datagrams UDP buffer size: 208 KByte ( default ) ----------------------------------------------------------- [ 3 ] local 192.168.1.100 port 55272 connected with 192.168.1.101 port 5001 [ ID ] Interval Transfer Bandwidth [ 3 ] 0.0-10.0 sec 114 MB 95.8 Mbps [ 3 ] Sent 81483 datagrams [ 3 ] Server Report: [ 3 ] 0.0-10.0 sec 114 MB 95.7 Mbps 0.158 ms 0/81482 [ 3 ] 0.0-10.0 sec 1 datagrams received out-of-order 由于 UDP 是无状态连接，它不能像 TCP 知道在网络中到达多远。 所以 iperf 选择理性默认的发送 UDP 流量，默认目标1Mbps的吞吐量。 之前的例子则通过 -b 标志指定目标带宽为100Mbps。 你可能也注意到客户端的 UDP 视图中也显示了 Server Report。 这是必须的，因为 UDP 是没任何保证，客户端可以整天开心的发送数据包到服务端，然后被丢弃。 注意客户端和服务端的 UDP 比较结果应该是一致的。 MUltihost SSH Wrapper MUltihost SSH Wrapper，或者叫 mussh ，是今天看来任然好用的古老工具。 核心上，mussh 仅是个封装了 SSH 的 shell 脚本，允许你跨多台主机串行或并行的执行相同命令。 这个脚本填补了一个跨分布式系统一次性运行命令的缺口，直到最近很多 CM 工具的出现被忽略。 已经有了配置管理工具，为什么我可能想做以外的事情呢？ 你应该用\"大锤子\"执行系统状态，虽然这是事实，但有时你仅需要一次或者不经常执行任务。 以 NTP 时钟偏差为例。 我最近遇到个问题，服务在硬件升级后网络排队时间戏剧性地增加了。 NTP 配置和服务状态都通过 CM 执行，所以我知道它在运行。 我想核实所有系统时钟都被同步，而且不想每个都手动远程 ssh 上去。 $ mussh -l pi -m 2 -h rpi-1 rpi-2 -c 'sudo ntpdate -u ntp.home' pi@rpi-1: ntpdate: adjust time server ntp.home offset 0.0151 sec pi@rpi-2: ntpdate: adjust time server ntp.home offset 0.0006 sec 哇，这是长命令。所以来分解下吧。 Sync NTP across multiple hosts concurrently $ mussh \\ -l pi \\ # Set the ssh username -m 2 \\ # Run on two hosts concurrently -h rpi-1 rpi-2 \\ # Hostnames for the command -c ‘sudo ntpdate -u ntp.home' # Sync ntp with this peer 输出结果是 hostname: output of the command 这个格式，这在你期望单行运行命令时是有帮助的。 如果你预计每个主机多行输出，你可以通过传递 -b 选项给 mussh 输出缓冲区,否则所有系统的输出显示交织在一起。 在这个例子中我们使用了3个假设。 首先，在你的电脑和主机列表之间使用基于密钥的 ssh 认证（你在使用密钥对吧？）。 你还需要运行 key-agent ，使得不用每台主机都提示输入私钥。 最后，这个例子假设用户 pi 无需输入密码就可执行 sudo ntpdate ， 这个适用于实验环境演示，但不是生产环境的最佳实践。 嗯，这是个好年代，但我不希望为每个命令都输入主机名！ 幸运的是，mussh 支持 -H 选项，从文件中每次读取一行为主机。 于是可以从你有的任何存储机制（文件、数据库、RESTful）中抓取，管道输入。 $ grep \"rpi-\" servers.txt | mussh -l pi -H - -c 'uptime' pi@rpi-1: 21:12:54 up 4 days, 23:18, 1 user, load average: 0.00 pi@rpi-2: 21:12:54 up 4 days, 23:18, 1 user, load average: 0.00 在这个片段中，从一个文本文件中过滤我的 Raspberry Pi 服务器，并发送给 mussh。 秘诀是 -H - 告诉 mussh 从 stdin 读取文件。 Conclusion 温故而知新。 过去的工具依然存在，激励创新，使我们大胆的更新换代。 这里讨论的工具继任者还在起步阶段。 其中一些仍在积极的开发，蜂拥的使用促使开发者们把它们推到下一个级别。 All of them have contributed to getting us where we are today and deserve if nothing else a tip of the hat. PS：翻译的比较烂 Orz，最后一句还没整明白。后期可以润色下，有些地方太生涩了。","tags":"Devops","title":"5款经典的 DevOps 工具"},{"url":"http://www.7rack.info/monitoring-solution-with-python.html","text":"SNMP简单介绍 是IP网络的设备管理协议，通过UDP的161和162端口实现。 snmpd具有一个保持追踪的对象列表，有MIB（管理信息库）进行控制。 MIB文件内是被管理对象的定义，有三个属性名称、类型和语法，以及编码。 名称经常作为OID（对象标识）被引用，有数字和文本类型。 snmpwalk -v 2c -c public localhost .1.3.6.1.2.1.1.1.0 snmpwalk -v 2c -c public localhost sysDescr Net-SNMP 如果只需简单的监控，自己开发，在 Python 平台下的 Net-SNMP 是个不错的选择。 可以使用两类不同的 API 。使用 subprocess 模块封装 Net-SNMP 命令行工具；或使用新的 Python 绑定。 #!/usr/bin/env python import netsnmp class Snmp ( object ): \"\"\"A basic SNMP session\"\"\" def __init__ ( self , oid = \"sysDescr\" , Version = 2 , DestHost = \"localhost\" , Community = \"public\" ): self . oid = oid self . version = Version self . destHost = DestHost self . community = Community def query ( self ): \"\"\"Creates SNMP query session\"\"\" try : result = netsnmp . snmpwalk ( self . oid , Version = self . version , DestHost = self . destHost , Community = self . community ) except Exception , err : print err result = None return result 以上代码摘自 py4sa 。 Zenoss 据官方说明，Zenoss 是开源的，同时也是很好的 Python 下企业级SNMP监测方案。 可以通过公共 API 来与其通信。为 Zenoss 写一个插件、补丁或是扩展 Zenoss 本身都是可行的。 安装 Zenoss 也比较简单的，需要较好的网络环境，否则让人崩溃的延时等待... 既然是企业级应用，各种功能都比较全。运行时比 nagios + cacti 耗费资源，可以看到运行的服务： # service zenoss status Daemon : zeneventserver program running ; pid = 55706 Daemon : zopectl program running ; pid = 55914 Daemon : zenrrdcached program running ; pid = 55919 Daemon : zenhub program running ; pid = 55992 Daemon : zenjobs program running ; pid = 56074 Daemon : zeneventd program running ; pid = 56138 Daemon : zenping program running ; pid = 56248 Daemon : zensyslog program running ; pid = 56403 Daemon : zenstatus program running ; pid = 56387 Daemon : zenactiond program running ; pid = 56437 Daemon : zentrap program running ; pid = 56631 Daemon : zenmodeler program running ; pid = 56629 Daemon : zenperfsnmp program running ; pid = 56672 Daemon : zencommand program running ; pid = 56746 Daemon : zenprocess program running ; pid = 56801 Daemon : zredis program running ; pid = 56805 Daemon : zenpython program running ; pid = 56866 Daemon : zenjmx program running ; pid = 56938 Zenoss 与 Google 地图 mashup 来显示设备位置，自己倒是想过:) 不过还有这里还有没想过的feature","tags":"Monitoring","title":"Python平台下监控实现"},{"url":"http://www.7rack.info/devstack-installation-and-create-instance-with-cli.html","text":"安装DevStack 由于在内地的网络环境问题，直接按照DevStack官方网站的方法安装会遇到一系列的问题，在此不吐槽了Orz。 我是选择OpenStack on Hardware且是 All-In-One 的环境搭建。 按照 All-In-One 中 Add your user 创建完stack用户设置好权限后， 接下来对网络环境进行一些设置。 设置pip 设置使用豆瓣pypi源 vim ~/.pip/pip.conf ,注意是以stack用户登录，如果.pip目录不存在需自行创建。 [global] index-url = http://pypi.douban.com/simple/ 设置Ubuntu源 设置Ubuntu系统镜像源，可参看163的Ubuntu镜像 使用帮助 。然后按照 All-In-One 中 Download DevStack 去下载DevStack。 配置local.conf 在运行之前需编辑 local.conf 文件，具体还是参看 All-In-One 中 Run DevStack 。 如果就这样运行 ./stack.sh 的话，还是会各种超时！ 我们可以不使用github repo，改用国内的oschina或者csdn repo，在 local.conf 中另外加入 GIT_BASE=https://git.oschina.net #or csdn repo #GIT_BASE=https://code.csdn.net 运行后，你就可以通过dashboard来操作，添加实例。接下来我使用CLI去完成一个简单的添加实例。 创建实例 在这之前需要 source 环境变量，运行 source openrc 即可。 如果对命令有问题，可以使用 nova help 相关命令来查看帮助。 创建keypair 创建SSH keypair 并添加到Nova : ssh-keygen -f ~/.ssh/id_rsa -t rsa -N '' nova keypair-add --pub_key ~/.ssh/id_rsa.pub default_key 设置security group 编辑\"default\" Security Group 以允许 SSH 和 ICMP： nova secgroup-add-rule default tcp 22 22 0.0.0.0/24 nova secgroup-add-rule default icmp -1 -1 0.0.0.0/24 创建glance镜像 这里以ubuntu 12.04为例 wget http://cloud-images.ubuntu.com/precise/current/precise-server-cloudimg-amd64-disk1.img 上传该镜像 glance image-create --name ubuntu12.04 --is-public=true --container-format=bare --disk-format=qcow2 --file precise-server-cloudimg-amd64-disk1.img 然后可以通过 glance image-list 查看镜像是否上传正确。 启动镜像 首先查看有哪些flavor可以使用，运行 nova flavor-list 列出当前flavor。 启动刚上传的镜像： nova boot --flavor m1.medium --image ubuntu12.04 --key-name default_key ubuntuinstance 查看刚启动的实例状态 nova list nova show ubuntuinstance 如果是可用状态，可以检查该实例的console以检查启动状态 nova console-log ubuntuinstance SSH 登录实例 先列出所有的namespaces： ip netns 这个输出应该包含2行，一行以 qrouter 开头，另一行以 qdhcp 开头。 从 qdhcp 的namesapce登录实例。 ip netns exec qdhcp-c73d082f-d7ed-4b53-ac93-7a6a4c3fa3aa ssh -i default_key ubuntu@ubuntuinstance 更多的命令资料还是在OpenStack的 doc 文件中。","tags":"Cloud","title":"DevStack安装并使用CLI创建实例"},{"url":"http://www.7rack.info/creating-kvm-guest-on-ubuntu.html","text":"设置BIOS支持KVM 一般来说在BIOS设置菜单里，选择Advanced Step → CPU Options， 以确认Intel Virtualization Technology 选项是否 Enabled。 开机进入系统后，可以通过以下命令检查系统处理器是否支持KVM： grep -E 'vmx|svm' /proc/cpuinfo flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx lahf_lm ida arat epb xsaveopt pln pts dtherm tpr_shadow vnmi flexpriority ept vpid 如果有返回值，说明系统是支持KVM的。 vmx 功能标识指代Intel VT芯片， svm 功能标识指代AMD-V芯片。 安装KVM 这里很简单: apt-get install kvm 设置网络 首先需安装bridge-utils: apt-get install bridge-utils 如果你的host主机安装了桌面环境，需要禁止 Network Manager ： update-rc.d network-manager disable /etc/init.d/network-manager stop 编辑 /etc/network/interfaces ，像下面一样： auto lo iface lo inet loopback # The primary network interface auto virbr0 iface virbr0 inet static bridge_ports eth0 address 10.49.4.244 netmask 255.255.255.0 gateway 10.49.4.1 dns-nameservers 10.1.1.100 #如果是在dhcp的网络环境中，可用以下配置 #auto virbr0 #iface virbr0 inet dhcp # bridge_ports eth0 重启networking服务，以激活virbr0网桥，并查看： # /etc/init.d/networking restart # brctl show bridge name bridge id STP enabled interfaces virbr0 8000.265f1a9f1c6e no eth0 $ ifconfig eth0 Link encap:以太网 硬件地址 d4:be:d9:99:0d:e5 inet6 地址: fe80::d6be:d9ff:fe99:de5/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 跃点数:1 接收数据包:15163805 错误:0 丢弃:0 过载:0 帧数:0 发送数据包:323948 错误:0 丢弃:0 过载:0 载波:0 碰撞:0 发送队列长度:1000 接收字节:14043073032 (14.0 GB) 发送字节:159989689 (159.9 MB) 中断:20 Memory:e1a00000-e1a20000 virbr0 Link encap:以太网 硬件地址 26:5f:1a:9f:1c:6e inet 地址:10.49.4.244 广播:10.49.4.255 掩码:255.255.255.0 inet6 地址: fe80::d6be:d9ff:fe99:de5/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 跃点数:1 接收数据包:14827415 错误:0 丢弃:31 过载:0 帧数:0 发送数据包:245653 错误:0 丢弃:0 过载:0 载波:0 碰撞:0 发送队列长度:0 接收字节:13718846920 (13.7 GB) 发送字节:149494998 (149.4 MB) 创建KVM guest 安装FreeBSD10.0 建立disk image(qcow2)，使用qemu-img命令： qemu-img create -f qcow2 ~/vm/image.qcow2 10G 创建guest os： kvm -smp 4 -drive file = /home/xxx/vm/image.qcow2,if = virtio -cdrom /tmp/FreeBSD-10.0-RELEASE-amd64-bootonly.iso -m 1024 -nographic -curses -net nic,model = e1000 -net tap -boot d 以上命令 -smp 4 设置4 CPUs（默认是1）， -m 1024 设置内存1024M（默认128M）， -nographic -curses 设置从serial console 安裝， -net nic,model=e1000 -net tap 设置Guest OS 使用 e1000，直接bridge到virbr0。 在安装过程中选择static IP。 安装完成后创建个脚本，用以快捷启动guest os： #! /bin/bash kvm -smp 4 -drive file = /home/xxx/vm/freebsd.qcow2,if = virtio \\ -m 1024 -display none -daemonize \\ -net nic,model = e1000 -net tap -daemonize 使得guest os在初始后在后台运行， virtio 提高了i/o 性能，概念上是半虚拟化 hypervisor 中位于设备之上的抽象层。 安装CentOS6.5 在文本模式下安装CentOS还是要多个步骤，通过实验使用 -curses 或者 -nographic 参数直接加载minimal.iso是没有成功。可通过 -append console=ttyS0 参数来重定向guest的console。 获得启动kernel和initrd文件 mount /tmp/CentOS-6.5-x86_64-minimal.iso /mnt/ -o loop 创建guest os qemu-system-x86_64 -enable-kvm -m 1024 -smp 4 -hda vm/vm/centos6.5.qcow2 -cdrom /tmp/CentOS-6.5-x86_64-minimal.iso -nographic -append console = ttyS0 -kernel /mnt/isolinux/vmlinuz -initrd /mnt/isolinux/initrd.img -net nic,model = e1000 -net tap -boot d 这样的text安装界面有些错位 囧 。可看下图 创建启动脚本 安装完成后重启，下次开机使用下面的脚本启动。 #! /bin/bash qemu-system-x86_64 -enable-kvm -m 1024 -smp 4 \\ /home/xxx/vm/centos6.5.qcow2 -nographic -daemonize \\ -net nic,model = e1000 -net tap 最后可以看看网络的情况： # brctl show bridge name bridge id STP enabled interfaces virbr0 8000.0ede79ae20ca no eth0 tap0 tap1 # ifconfig -a eth0 Link encap:以太网 硬件地址 d4:be:d9:99:0d:e5 inet6 地址: fe80::d6be:d9ff:fe99:de5/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 跃点数:1 接收数据包:15308150 错误:0 丢弃:0 过载:0 帧数:0 发送数据包:368549 错误:0 丢弃:0 过载:0 载波:0 碰撞:0 发送队列长度:1000 接收字节:14169794107 (14.1 GB) 发送字节:172651372 (172.6 MB) 中断:20 Memory:e1a00000-e1a20000 tap0 Link encap:以太网 硬件地址 2e:5d:7b:be:b8:18 inet6 地址: fe80::2c5d:7bff:febe:b818/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 跃点数:1 接收数据包:66 错误:0 丢弃:0 过载:0 帧数:0 发送数据包:6801 错误:0 丢弃:0 过载:0 载波:0 碰撞:0 发送队列长度:500 接收字节:11671 (11.6 KB) 发送字节:6293612 (6.2 MB) tap1 Link encap:以太网 硬件地址 0e:de:79:ae:20:ca inet6 地址: fe80::cde:79ff:feae:20ca/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 跃点数:1 接收数据包:96 错误:0 丢弃:0 过载:0 帧数:0 发送数据包:4239 错误:0 丢弃:36 过载:0 载波:0 碰撞:0 发送队列长度:500 接收字节:11186 (11.1 KB) 发送字节:3879188 (3.8 MB) virbr0 Link encap:以太网 硬件地址 0e:de:79:ae:20:ca inet 地址:10.49.4.244 广播:10.49.4.255 掩码:255.255.255.0 inet6 地址: fe80::d6be:d9ff:fe99:de5/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 跃点数:1 接收数据包:14970219 错误:0 丢弃:31 过载:0 帧数:0 发送数据包:287199 错误:0 丢弃:0 过载:0 载波:0 碰撞:0 发送队列长度:0 接收字节:13842638850 (13.8 GB) 发送字节:161783854 (161.7 MB) 下次用该学学使用 virt-manager 来管理虚拟机。","tags":"Virtualization","title":"Ubuntu上运行KVM创建虚拟机"},{"url":"http://www.7rack.info/issues-of-Feb.html","text":"cmd 让当前目录下的文件和文件夹按大小排序输出，一开始把问题想复杂了。 可以通过一句命令,可读性也很好： # du -hs * | sort -h 0 misc 0 net 0 proc 0 sys 4.0K media 4.0K mnt 4.0K srv 16K lost+found 24K ftp 100K home 164K dev 4.3M opt 7.6M bin 11M tmp 14M sbin 25M lib64 34M etc 39M boot 125M lib 158M var 442M root 2.9G usr ssh 当尝试通过域名连接一个 IP 已经变动（或经常变动）的主机，出现 host key for 'foo.example.com' differs from the key for the IP address 'xxxx' 信息。 可通过创建 ~/.ssh/config 文件： Host foo Hostname foo.example.com CheckHostIP no Port 32513 User danny 然后就可以通过 ssh foo 来连接。进一步的解释，可查看 man 5 ssh_config 。 另外，在服务端最好禁用公钥认证以外的其他认证方式。 和公钥认证有关配置项是： #RSAAuthentication yes ：Specifies whether pure RSA authentication is allowed.This option applies to protocol version 1 only #PubkeyAuthentication yes ：Specifies whether public key authentication is allowed.Note that this option applies to protocol version 2 only. 其缺省值一般为 yes。 禁用其他的认证方式，需修改下列配置项： PasswordAuthentication no ChallengeResponseAuthentication no UsePAM no 详细的解释，可查看 man 5 sshd_config 。 双线动态路由 针对 CentOS 环境的设置 在 /etciproute2/rt_tables 中添加电信、网通路由表： 252 tel 251 cnc 在 /etc/init.d/network 的最后一行 exit $rc 前添加电信、网通路由表内容： ip route replace default via 电信网关 dev eth0 #默认路由线路 ip route flush table tel #刷新tel路由表 ip route add default via 电信网关 dev eth0 src 电信IP table tel #添加回环地址 ip rule add from 电信IP table tel #从电信IP过来的，走tel路由 ip route flush table cnc #刷新cnc路由表 ip route add default via 网通网关 dev eth1 src 网通IP table cnc ip rule add from 网通IP table cnc #从网通IP过来的走cnc路由 硬件 E2110 Multibit Error on DIMM B2. Reseat DIMM. 简单查了下是 插槽 \"B2\" 中的内存模块已发生多位错误 (MBE) 。 Dell 的技术支持页面也有说明： 内存错误可能会毁坏高速缓存的数据，所以控制器旨在检测到这些内存错误并尝试从这些内存错误中恢复。单位内存错误可以由固件处理而不影响正常运行。如果单位错误的数目超过了阈值，将发送通知。 多位错误更严重，因为此类错误会导致数据毁坏和数据丢失。以下是出现多位错误时采取的措施： 如果在使用恶劣高速缓存启动控制器时访问高速缓存内存中的数据而导致多位错误，则固件将放弃高速缓存内容。固件将生成警告信息并发送到系统控制台，指示已放弃高速缓存并将生成事件。 如果在运行时代码/数据或高速缓存中出现多位错误，则固件将停止。 固件会将事件记录到固件内部事件日志并将在 POST 过程中记录指示已出现多位错误的信息。 注：如果出现多位错误，请与 Dell 技术支持联络。","tags":"Linux","title":"问题集锦(二月)"},{"url":"http://www.7rack.info/bash-script-learning-note.html","text":"最近复习bash script一些模糊点，在此记下笔记，如有错误麻烦指出 单引号和双引号的区别： 如果变量被 双引号 引用，变量还是需要由shell来解释,而且一旦赋值给变量多个单词，shell翻译时就会自动取消空格； 如果变量被 单引号 引用，变量就不会发生替换。 eg: [ root@www ~ ] # grep -i \"$LOGNAME\" /etc/passwd root:x:0:0:root:/root:/bin/bash [ root@www ~ ] # grep -i '$LOGNAME' /etc/passwd [ root@www ~ ] # echo $? 1 同时让我想起在shell script中 $* 与 $@ 的分别。只有在用双引号引用时二者才有区别。 双引号中的 $* 使得变量变为一个字符串；而双引号中的 $@ ，相当于其中的每一个变量都被双引号引用，每一个单词都被看作分开的字符串。 let命令 let 是bash 的内建命令，用来做数学计算和数字表示法检测（后面与test一起介绍下）。 格式是： let expression (( expression )) eg： [ root@www ~ ] # i=1 [ root@www ~ ] # let \"i=i+2\" [ root@www ~ ] # echo $i 3 [ root@www ~ ] # ((i=i-2)) [ root@www ~ ] # echo $i 1 注意到它不用 $ 符号去引用变量，同时还有个不常用的计算数学表达式的格式 $[ expression ] test命令 格式 test for numbers and strings-- old format [ string/numeric expression ] test for strings-- new format [[ string expression ]] let for numbers-- new format (( numeric expression )) eg： [ root@www ~ ] # name=tom [ root@www ~ ] # friend=Jose [ root@www ~ ] # x=2 [ root@www ~ ] # y=2 [ root@www ~ ] # test $name != Tom [ root@www ~ ] # echo $? 0 [ root@www ~ ] # [[ $name == [Tt]om && $friend == \"Jose\" ]] [ root@www ~ ] # echo $? 0 [ root@www ~ ] # ((x== 2 && y == 3)) [ root@www ~ ] # echo $? 1","tags":"Linux","title":"Bash学习笔记"},{"url":"http://www.7rack.info/build-kindleear-on-gae.html","text":"昨天在找推送RSS到kindle的东西，发现了比较好的帖子 开源的kindleear 。因为之前搭建过Goagent，所以操作起来也很方便，很快就弄好了，这是我的 kindleear服务器 。 搭建的说明还是很详细，加上最近出了uploader，更方便。 2013-09-27，增加uploader，给不想安装python和GAE SDK的同学。 google drive 其中要注意一点就是上传结束后要访问你的站点时加上 https:\\\\ 即 https:\\\\app_name.appspot.com 。 PS：操作过程中，建议先搭梯子 goagent 。感谢这些技术男，高端大气上档次了O(∩_∩)O哈哈\\~","tags":"Uncategorized","title":"在GAE上搭建kindle推送服务器"},{"url":"http://www.7rack.info/encrypt.html","text":"介绍几个常用开源的加密工具： 资料加密：我之前用Ecryptfs在Debian系统下加密一些私人信息，要在terminal下使用，用起来也很方便。但是在windows下，解密不方便。不过是企业级的应用，很强大，具体使用可参看 wiki 。 现在用 TrueCrypt 觉得很好，首先在windows和类unix系统下都可以使用，有图形操作界面，体积一样很小。可以加密分区和设备（U盘）。 通讯加密：最近在网上闲逛，看到一 语音加密 工具叫 RedPhone ，也是开源技术，googleplay上已有android应用，双方通话时需都安装。同时还有个 TextSecure ，是用来加密短信，不光本地加密，通讯途中也是加密的。 密码保护：一直在用 KeePass ，为加密本地保存密码，可以根据需要生成随机密码。有android和桌面（包括windows、类unix）版本。我的方法是用Dropbox把他们同步起来，保持密码数据库文件的最新。 签名：PGP这个都是成为签名和加密的标准了，可配合thunderbird使用来签名加密邮件。详细的说明和使用参看 ubuntu wiki 。","tags":"Linux","title":"资料通讯加密"},{"url":"http://www.7rack.info/get-kindle-4.html","text":"最近淘了个kindle 4，为看pdf方便也装了个多看 嘿嘿。 想起上个月，跨入本命年第一天就失窃，丢电脑:(好难过。 发自 WordPress for Android","tags":"Uncategorized","title":"入手Kindle 4"},{"url":"http://www.7rack.info/geodjango-tutorial-2.html","text":"GeoDjango学习一 提到用ogrinspect命令自动产生model定义和 LayerMapping字典,命令的一般用法如下 $ python manage.py ogrinspect [options] <data_source> <model_name> [options] options 通常是 --mapping --multi ，具体查看man手册。 GeoDjango的tutorial文档中还举例通过GeoDjango Database API中的contains和intersects实现空间查找，也展示了空间投影转换和怠惰地理数据(Lazy Geometries)。 在runserver后我们可以登陆后台对world border进行修改、增加、删除操作。下面分别展示下OpenLayers默认提供的数据和OpenStreetMap 图层作为底图的效果 文中提到的 OpenStreetMap 是一个在线的地图协作项目，旨在创造一个免费开源的世界地图，也像Wikipedia（维基百科）一样，任何人可以创建和编辑。去创建个账户，上传轨迹编辑地图吧 哈哈","tags":"FreeGIS","title":"GeoDjango学习二（空间查询）"},{"url":"http://www.7rack.info/geodjango-tutorial.html","text":"GeoDjango是Django的衍生项目，旨在让创建地理web应用更简单。首先要搭建开发环境，最好根据官方文档 GeoDjango Installation 来安装，并注意Django的版本不同对应的文档也不同。我的系统环境是debian 7 安装PostgreSQL、PostGIS $sudo apt-get install postgresql-9.1 postgresql-9.1-postgis postgresql-server-dev-9.1 python-psycopg2 python-setuptools 安装Geospatial libraries $ sudo apt-get install binutils libgdal1 libproj-dev gdal-bin 最后安装Django 可查看安装的Django版本 $ python -c \"import django; print(django.get_version())\" 为了更方便的创建一个空间数据库，需预先创建一个template_postgis数据库。官方网站有写好的脚本create_template_postgis-debian.sh #!/bin/bash GEOGRAPHY = 0 POSTGIS_SQL = postgis.sql # For Ubuntu 8.x and 9.x releases. if [ -d \"/usr/share/postgresql-8.3-postgis\" ] then POSTGIS_SQL_PATH = /usr/share/postgresql-8.3-postgis POSTGIS_SQL = lwpostgis.sql fi # For Ubuntu 10.04 if [ -d \"/usr/share/postgresql/8.4/contrib\" ] then POSTGIS_SQL_PATH = /usr/share/postgresql/8.4/contrib fi # For Ubuntu 10.10 (with PostGIS 1.5) if [ -d \"/usr/share/postgresql/8.4/contrib/postgis-1.5\" ] then POSTGIS_SQL_PATH = /usr/share/postgresql/8.4/contrib/postgis-1.5 GEOGRAPHY = 1 fi # For Ubuntu 11.10 / Linux Mint 12 (with PostGIS 1.5) if [ -d \"/usr/share/postgresql/9.1/contrib/postgis-1.5\" ] then POSTGIS_SQL_PATH = /usr/share/postgresql/9.1/contrib/postgis-1.5 GEOGRAPHY = 1 fi createdb -E UTF8 template_postgis && ( createlang -d template_postgis -l | grep plpgsql || createlang -d template_postgis plpgsql ) && psql -d postgres -c \"UPDATE pg_database SET datistemplate='true' WHERE datname='template_postgis';\" && psql -d template_postgis -f $POSTGIS_SQL_PATH / $POSTGIS_SQL && psql -d template_postgis -f $POSTGIS_SQL_PATH /spatial_ref_sys.sql && psql -d template_postgis -c \"GRANT ALL ON geometry_columns TO PUBLIC;\" && psql -d template_postgis -c \"GRANT ALL ON spatial_ref_sys TO PUBLIC;\" if (( GEOGRAPHY )) then psql -d template_postgis -c \"GRANT ALL ON geography_columns TO PUBLIC;\" fi 可根据需要修改下。 下面就可以新建角色和数据库 $ sudo su - postgres postgres@7rack:~ $ createuser geo 新的角色是否是超级用户? ( y/n ) n 新的角色允许创建数据库吗? ( y/n ) y #这里必须是有创建数据库的权限 新角色允许创建其它新的角色吗? ( y/n ) y postgres@7rack:~ $ createdb -T template_postgis -O geo geodjango 然后就可以按照 GeoDjango Tutorial 开始实验项目，对于地理模型定义和LayerMapping字典数据，可用ogrinspect 管理命令来自动完成，比较方便。 参考文章： GeoDjango 教程 GeoDjango Document","tags":"FreeGIS","title":"GeoDjango学习一（开发环境搭建）"},{"url":"http://www.7rack.info/create-your-own-child-themes-under-twentytwelve.html","text":"子主题的介绍和制作可以查看 wordpress文档 ，简单的说一个wordpress子主题就像其他任何主题一样，你可以把她放在主题的目录下（/wp-content/themes）下， 她同样包含style.css、screenshot.png、脚本或者其他主题文件。同样可以在控制面板上激活她，只是她依赖父主题。 下面是我创建子主题时所做的： 给网站加上了favicon,通过在functions.php中add_action到head元素。 加入404公益，在益播网copy代码加入到404.php合适位置。 实现scroll to top功能，按照葵中剑's Blog中的 jQuery plugin - Scroll to Top 文章的DEMO实现，并copy了他的style。:) 在footer.php中加入知识共享许可协议。 把主内容区和总宽度都加大了，推荐使用firebug很容易找到想修改的部分。 实现的效果就是这样子 另外用Disqus comment system插件代替wordpress自带的评论系统，在第一次导入已有评论时花的时间蛮久。 做完子主题后看到有文章提到，应该用wp enqueue script来安全的加入javascript代码。下次再看看，最近瞎忙活，想学的东西实在太多了","tags":"WordPress","title":"Twenty Twelve下创建自己的Child Themes"},{"url":"http://www.7rack.info/desktop.html","text":"闲来无聊折腾桌面，debian dist-upgrade到testing了，FreeBSD用的xfce桌面环境，win7用的是Rainmeter来监视系统。","tags":"Uncategorized","title":"Desktop ScreenShot"},{"url":"http://www.7rack.info/music.html","text":"Girl I'm Gonna Miss You - Milli Vanilli Letting the Cables Sleep (Nightmares On Wax Remix) - Bush Angel Of Mine - Frank Duval Ready To Take A Chance Again - Barry Manilow Slim - Water I Want To Know What Love Is - Foreigner Moonlight Shadow - Mike Oldfield Wire - Jon Hopkins","tags":"Uncategorized","title":"Love music"},{"url":"http://www.7rack.info/miss-2012.html","text":"Wed,Dec 12,2012 \"乱烘烘你方唱罢我登场，反认他乡是故乡。甚荒唐，到头来都是 为他人做嫁衣裳.\" Tue, Nov 27 出门买早点，下霜了，好久不见，喜欢这样的四季更替。 Sun, Oct 28 看着日落月升，想着远方的他们此时此刻依然在为自己的梦想奋斗。飞机在远空划下金黄的轨迹，我依然在等待…痛彻心扉，苦往心里藏 Sun, Sep 14 清晨太阳那么柔和，整个空气都是新鲜而又清凉，刚走出大门我想起来这已经接近夏天的最后一个早晨了，叶子尖上的露珠被照得闪闪发光。 8月21日 想起好朋友说的人生很戏剧性，工作已近1月，现在的我很迷茫，看不清方向，时间总是飞快的走，剩下慌张的心。 7月7日 今天经过光谷广场的地下通道，听到小女孩生涩的唱邓丽君《月亮代表我的心》，旁边2位大哥哥在用guitar 伴奏.小时候熟悉的旋律，突然静了下来,这个城市也许并非很陌生。想起1996年的《甜蜜蜜》中俩人在纽约街头的重逢，看到邓丽君逝世的消息时，响起也是这首耳熟能详的歌。 6月25日 天黑了，一下子对现在的一切留恋起来。好想说，留下来吧！留下来吧！即使不为我，也为了这迷人的夜色，然而我什么也没说。回来的路，一个人走。有时真恨自己... May 28 见到笑容的那一刻，考试就变得极不重要，觉得那是不会有的事，明天也是不会来的。渐渐担心我们岂是真的就此分开了... ...美好的东西总是稍纵即逝. 00:16:42 人生是一场大梦，多年来无论我在高中学校，在家，在大学 ，有时突然醒来，总有那么几秒钟要想，我是谁，我在哪里 。","tags":"Uncategorized","title":"遇见2012"},{"url":"http://www.7rack.info/advice-to-graduates.html","text":"作者：胡适 来源：原载1932年7月3日《独立评论》第7号 这一两个星期里，各地的大学都有毕业的班次，都有得多的毕业生离开学校去开始他们的成人事业。 学生的生活是一种享有特殊优待的生活，不劣稚一点，不脸吵闹闹，社会都能纵容他们，不肯严格的要他们负行为的责任。 现在他们要撑起自己的肩膀来挑他们自己的担子了。 在这个国难最紧急的年头，他们的担子真不轻!我们祝他们的成功，同时也不忍不依据自己的经验，赠他们几句送行的赠言，虽未必是救命毫毛，也许做个防身的锦囊罢! 你们毕业之后，可走的路不出这几条： 绝少数的人还可以在国内或国外的研究院继续做学术研究; 少数的人可以寻着相当的职业; 此外还有做官，办党，革命三条路; 此外就是在家享福或者失业亲居了。 走其余几条路的人，都不能没有堕落的危险。堕落的方式很多，总括起来，约有这两大类： 第一是容易抛弃学生时代求知识的欲望。 你们到了实际社会里，往往学非所用，往往所学全无用处，往往可认完全用不着学问，而一样可认胡乱混饭吃，混官吃。 在这种环境里即使向来抱有求知识学问的人，也不免心灰意懒，把求知的欲望渐渐冷淡下去。 况且学问是要有相当的设备的, 书籍，实验室，师友的切磋指导，闲暇的工夫，都不是一个平常要糊口养家的人的能容易办到的。 没有做学问的环境，又谁能怪我们抛弃学问呢? 第二是容易抛弃学生时代理想的人生的追求。 少年人初次和冷酷的社会接触，容易感觉理想与事实相去太远，容易发生悲观和失望。 多年怀抱的人生理想，改造的热诚，奋斗的勇气，到此时候，好像全不是那么一回事了。 渺小的个人在那强烈的社会炉火里，往往经不起长时期的烤炼就熔化了，一点高尚的理想不久就幻灭了。 抱着改造社会的梦想而来，往往是弃甲抛兵而走，或者做了恶势的俘虏。 你在那牢狱里，回想那少年气壮时代的种种理想主义，好像都成了自误误人的迷梦!从此以后，你就甘心放弃理想人生的追求，甘心做现在社会的顺民了。 要防御这两方面的堕落，一面要保持我们求知识的欲望，一面要保持我们对人生的追求。 有什么好方法子呢?依我个人的观察和经验，有三种防身的药方是值得一试的。 第一个方子只有一句话：\"总得时时寻一两个值得研究的问题!\"问题是知识学问的老祖宗;古 往今来一切知识的产生与积聚，都是因为要解答问题，--要解答实用上的困难和理论上的疑难。 所谓\"为知识而求知识\"，其实也只是一种好奇心追求某种问题的解答，不过因为那种问题的性质不必是直接应用的，人们就觉得这是无所谓的求知识了。 我们出学校之后，离开了做学问的环境，如果没有一二个值得解答的问题在脑子里盘旋，就很难保持求学问的热心。 可是，如果你有了一个真有趣的问题逗你去想他，天天引诱你去解决他，天天对你挑衅你无可奈何他，这时候，你就会同恋爱一个女子发了疯一样，坐也坐不下，睡也睡不安，没工夫也得偷出工夫去陪她，没钱也得缩衣节食去巴结她。 没有书，你自会变卖家私去买书; 没有仪器，你自会典押衣物去置办仪器;没有师友，你自会不远千里去寻师访友。 你只要有疑难问题来逼你时时用脑子，你自然会保持发展你对学问的兴趣，即使在最贫乏的知识中，你也会慢慢的聚起一个小图书馆来，或者设置起一所小试验室来。 所以我说，第一要寻问题。脑子里没有问题之日，就是你知识生活寿终正寝之时! 古人说，\"待文王而兴者，凡民也。若夫豪杰之士，虽无文王犹 兴。\"试 想伽利略(GALIEO)和牛顿(NEWTON)有多少藏书?有多少仪器?他们不过是有问题而己。 有了问题而后他们自会造出仪器来解决他们的问题。没有问题的人们，关在图书馆里也不会用书，锁在试验室里也不会有什么发现。 第二个方子也只有一句话：\"总得多发展一点非职业的兴趣，\"离离开学校之后， 大家总是寻个吃饭的职业。可是你寻得的职业未必就是你所学的，未必是你所心喜的，或者是你所学的而和你性情不相近的。 在这种情况之下，工作往往成了苦工，就感觉不到兴趣了。 为糊口而做那种非\"性之所近而力之所能勉\"的工作，就很难保持求知的兴趣和生活的理想主义。最 最好的救济方法只有多多发展职业以外的正当兴趣与活动。 一个人应该有他的职业，也应该有他非职业的玩艺儿，可以叫做业余活动。 往往他的业余活动比他的职业还更重要，因为一个人成就怎样，往往靠他怎样利用他的闲暇时间。 他用他的闲暇来打麻将，他就成了个赌徒;你用你的闲暇来做社会服务，你也许成个社会改革者;或者你用你的闲暇去研究历史，你也许成个史学家。你的闲暇往往定你的终身。 英国十九世纪的两个哲人，弥儿(J.S.MILL)终身做东印度公司的秘书，然而他的业余工作使他在哲学上，经济学上，政治思想史上都占一个很高的位置; 斯宾塞(SPENCER)是一个测量工程师，然而他的业余工作使他成为前世纪晚期世界思想界的一个重镇。 古来成大学问的人，几乎没有一个不善用他的闲暇时间的。 特别在这个组织不健全的社会，职业不容易适合我们的性情，我们要想生活不苦痛不堕落，只有多方发展。 有了这种心爱的玩艺，你就做六个钟头抹桌子工作也不会感觉烦闷了，因为你知道，抹了六个钟的桌子之后，你可以回家做你的化学研究，或画完你的大幅山水，或写你的小说戏曲，或继续你的历史考据，或做你的社会改革事业。 你有了这种称心如意的活动，生活就不枯寂了，精神也就不会烦闷了。 第三个方法也只有一句话：\"你得有一点信心。\"我 我们生当这个不幸的时代，眼中所见，耳中所闻，无非是叫我们悲观失望的。 特别是在这个年头毕业的你们，眼见自己的国家民族沉沦到这步田地，眼看世界只是强权的世界，望极天边好像看不见一线的光明。 在这个年头不发狂自杀，已算是万幸了，怎么还能够保持一点内心的镇定和理想的信任呢? 我要对你们说：这时候正是我们要培养我们的信心的时候!只要我们有信心，我们还有救。 古人说：\"信心(FAITH)可以移 山。\"又说：\"只要工夫深，生铁磨成绣花针。\"你不你不信吗? 当拿破仑的军队征服普鲁士，占据柏林的时候，有一位教授叫做费希特(FICHTE)的，天天在讲堂劝他的国人要有信心，要信仰他们的民族是有世界的特殊使命的，是必定要复兴的。费希特死的时候，谁也不能预料德意志统一帝国何时可以实现。然而不满五十年，新的统一的德意志帝国居然实现了。 一个国家的强弱盛衰，都不是偶然的，都不能逃出因果的铁律的。 我们今日所受的苦痛和耻辱，都只是过去种种恶因种下的恶果。 我们要收获将来的善果，必须努力种现在新因。一粒一粒的种，必有满仓满屋的收，这是我们今日应有的信心。 我们要深信：今日的失败，都由于过去的不努力。我们要深信：今日的努力，必定有将来的大收成。 佛典里有一句话：\"福不唐捐。\"唐捐就是白白的丢了。我们也应该说：\"功不 唐捐!\"没有一点努力是会白白的丢了的。在 我们看不见想不到的时候，在我们看不见的方向，你瞧!你下的种子早已生根发叶开花结果了!你不信吗? 法国被普鲁士打败之后，割了两省地，赔了五十万万法朗的赔款。这时候有一位刻苦的科学家巴斯德(PASTEUR)终日埋头在他的化学试验室里做他的化学试 验和微菌学研究。他是一个最爱国的人然而他深信只有科学可以救国。他用一生的精力证明了三个科学问题： (1)每一种发酵作用都是由于一种微菌的发展; (2)每一种传染病都是一种微菌在生物体内的发展; (3)传染病的微菌，在特殊的培养之下可以减轻毒力，使他们从病菌变成防病的药苗。 这三个问题在表面上似乎都和救国大事业没有多大关系。然而从第一个问题的证明，巴斯德定出做醋酿酒的新法，使全国的酒醋业每年减除极大的损失。从第二个问题的证明巴斯德教全国的蚕丝业怎样选种防病，教全国的畜牧农家怎样防止牛羊瘟疫，又教全世界怎样注重消毒以减少外科手术的死亡率。 从第三个问题的证明，巴斯德发明了牲畜的脾热瘟的疗治药苗，每年替法国农家减除了二千万法朗的大损失;又发明了疯狗咬毒的治疗法，救济了无数的生命。所以英国的科学家赫胥黎(HUXLEY)在皇家学会里称颂巴斯德的功绩道：\"法国给了德国五十万万法朗的赔款，巴斯德先生一个人研究科学的成就足够还清这一笔赔款了。\" 巴斯德对于科学有绝大的信心，所以他在国家蒙奇辱大难的时候，终不肯抛弃他的显微镜与试验室。他绝不想他有显微镜底下能偿还五十万万法朗的赔款，然而在他看不见想不到的时候，他已收获了科学救国的奇迹了。 朋友们，在你最悲观失望的时候，那正是你必须鼓起坚强的信心的时候。你要深信：天下没有白费的努力。 成功不必在我，而功力必不唐捐 。","tags":"Uncategorized","title":"赠与毕业生"},{"url":"http://www.7rack.info/sound-driver-problem-on-freebsd.html","text":"官方文档见 安装声卡 。 1. 查找声卡型号 localhost# dmesg | grep pcm pcm0: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> at cad 0 nid 1 on hdac0 pcm1: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> at cad 1 nid 1 on hdac0 pcm2: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> at cad 2 nid 1 on hdac0 pcm3: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> at cad 3 nid 1 on hdac0 pcm4: <HDA Realtek ALC269 PCM #0 Analog> at cad 0 nid 1 on hdac1 pcm5: <HDA Realtek ALC269 PCM #1 Digital> at cad 0 nid 1 on hdac1 pcm6: <HDA Realtek ALC269 PCM #2 Analog> at cad 0 nid 1 on hdac1 2. 装载正确的驱动，有上可见我的声卡型号是Intel High Definition Audio （HDA）[详见][]，更多支持的声卡见[hardware][]。因为我对定制内核还不熟悉，所以选择boot时装载驱动。`echo 'snd_hda_load=\"YES\"' >>/boot/loader.conf` 3. 这样应该就可以了，但是自从安装了nvidia显卡驱动后，声音又不正常了。通过 `/dev/sndstat` 文件来查询声卡的状态： localhost# cat /dev/sndstat FreeBSD Audio Driver ( newpcm: 32bit 2009061500/i386 ) Installed devices: pcm0: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> (play) default pcm1: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> (play) pcm2: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> (play) pcm3: <HDA NVidia GT220 HDMI PCM #0 DisplayPort> (play) pcm4: <HDA Realtek ALC269 PCM #0 Analog> (play/rec) pcm5: <HDA Realtek ALC269 PCM #1 Digital> (play) pcm6: <HDA Realtek ALC269 PCM #2 Analog> (rec) 可见此处显卡 ( NVidia ) 先于真正的声卡 ( Realtek ALC269 ) 被探测到，且作为默认的回放设备。 需将pcm4作为默认的回放设备 #echo 'hw.snd.default_unit=4' >> /etc/sysctl.conf","tags":"FreeBSD","title":"解决FreeBSD下声卡驱动问题"},{"url":"http://www.7rack.info/image-transform-template-with-cuda-opencv.html","text":"由于毕业设计的需要，自学了点opencv和cuda编程。下面的代码涉及到CUDA C中的几个知识点在此列出： 纹理存储器（Texture memory）：纹理缓存中的数据可以被重复利用，当一次访问需要的数据已经存在于纹理内缓存中时，就可以避免对显存的再次读取。数据重用过滤了一部分对显存的访问，节约了带宽，也不必按照显存对其的要求读取。其次，纹理缓存一次预取拾取坐标对应位置附近的几个像元，可以实现滤波模式，也可以提高具有一定局部性的访存的效率。 CUDA 数组：使用纹理存储器时，首先要在主机端声明需要绑定到纹理的线性存储器或CUDA 数组，并设置好纹理参照系，然后将纹理参照系与线性存储器或者CUDA数组绑定。 线程组织：每个Grid 中由((src_w+dimBlock.x-1)/dimBlock.x, (src_h+dimBlock.y-1)/dimBlock.y,1)个block，使用这种形式来表示block 的维度，是为了保证block 的数量是一个整数，并且整个grid 中的thread 数量比实际处理的元素数量要多。这样做还有另外一个好处;一个grid 中的block 数量只与问题的规模有关，而与实际的硬件设备中拥有多少个处理核心没有关系。由于各个block 在处理核心上独立运行，因此可以在规格不同的硬件上处理相同的问题，只是拥有更多核心的GPU 可以在更短的时间内完成计算。 另外这个小模版也有缺陷，实现的是灰度图的变换。如果要实现彩色图像的变化，我想还要用到uchar4数据类型，我曾实验过，但是结果图有点诡异是3幅相同的图并列显示，图的变换结果也不对。后来为了赶进度就放弃，改为实现灰度图的变换，因为我的主要是加速。如果哪位网友实现了原图像通道数变换，望能指点下:) #include <cv.h> #include <highgui.h> #include <cutil_inline.h> #include <stdio.h> #include <stdlib.h> #define FILENAME \"parameters.txt\" texture texsrc ; __global__ void transform ( uchar * dstdata , int width , int height ) { //将threadIdx/BlockIdx映射到像素位置 int u = threadIdx . x + blockIdx . x * blockDim . x ; int v = threadIdx . y + blockIdx . y * blockDim . y ; float u_coor , v_coor ; //对像素点进行变换（需实现的功能） /*u_coor = (xtmp/param[3]); v_coor = (ytmp/param[3]); delta_u = u_coor - (int)u_coor; delta_v = v_coor - (int)v_coor; */ u_coor /= ( float ) width ; v_coor /= ( float ) height ; //灰度重采样（双线性） //纹理拾取(linear) dstdata [ v * width + u ] = 255 * tex2D ( texsrc , u_coor , v_coor ); //纹理拾取(point)自己来实现双线性插值 /*dstdata[v * width + u] = 255*(1-delta_u)*(1-delta_v)*tex2D(texsrc, u_coor, v_coor)+ (1-delta_u)*delta_v*tex2D(texsrc, u_coor, v_coor+1)+ delta_u*(1-delta_v)*tex2D(texsrc, u_coor+1, v_coor)+ delta_u*delta_v*tex2D(texsrc, u_coor+1, v_coor+1); */ } int main ( int argc , char ** argv ) { IplImage * src_img , * dst_img ; if (( argc == 3 ) && (( src_img = cvLoadImage ( argv [ 1 ], 0 )) != 0 )) //强制转化读取图像为灰度图 { int src_w = src_img -> width ; int src_h = src_img -> height ; dst_img = cvCloneImage ( src_img ); dst_img -> origin = src_img -> origin ; cvZero ( dst_img ); int dst_h = dst_img -> height ; int dst_w = dst_img -> width ; int dst_size = dst_h * dst_w ; FILE * fin ; /* 打开参数文件 */ fin = fopen ( FILENAME , \"r\" ); if ( fin == ( FILE * ) 0 ) exit ( - 1 ); /* double *arr; arr=(double *)malloc(sizeof(double )*(DISTORTION_NUM+4)); if(arr==NULL) { printf(\"no memory\\n\"); return 1; } int i = 0; while ( !feof(fin)){ fscanf( fin,\"%lf\",&arr[i++]); } */ fclose ( fin ); //记录起始时间 cudaEvent_t start , stop ; cutilSafeCall ( cudaEventCreate ( & start )); cutilSafeCall ( cudaEventCreate ( & stop )); cutilSafeCall ( cudaEventRecord ( start , 0 )); //在显存上为CUDA Array分配空间 cudaChannelFormatDesc channelDes = cudaCreateChannelDesc (); cudaArray * srcArray ; cudaMallocArray ( & srcArray , & channelDes , src_w , src_h ); //向显存中拷贝数据 cudaMemcpy2DToArray ( srcArray , 0 , 0 , src_img -> imageData , sizeof ( uchar ) * src_img -> widthStep , sizeof ( uchar ) * src_img -> width , src_img -> height , cudaMemcpyHostToDevice ); //设置纹理参数 //循环寻址模式 texsrc . addressMode [ 0 ] = cudaAddressModeWrap ; texsrc . addressMode [ 1 ] = cudaAddressModeWrap ; //线性滤波模式 texsrc . filterMode = cudaFilterModeLinear ; texsrc . normalized = 1 ; //数组绑定到纹理 cudaBindTextureToArray ( texsrc , srcArray , channelDes ); //为纠正结果分配显存空间 uchar * dst_data ; cudaMalloc (( void ** ) & dst_data , dst_size * dst_img -> nChannels * sizeof ( uchar )); dim3 dimBlock ( 16 , 16 , 1 ); dim3 dimGrid (( src_w + dimBlock . x - 1 ) / dimBlock . x , ( src_h + dimBlock . y - 1 ) / dimBlock . y , 1 ); //调用设备端函数 transform <<>> ( dst_data , src_w , src_h ); cutilCheckMsg ( \"transform failed\" ); cudaThreadSynchronize (); cutilSafeCall ( cudaMemcpy ( dst_img -> imageData , dst_data , dst_size * dst_img -> nChannels * sizeof ( uchar ), cudaMemcpyDeviceToHost )); //获得结束时间，并显示计时结果 cutilSafeCall ( cudaEventRecord ( stop , 0 )); cutilSafeCall ( cudaEventSynchronize ( stop )); float elapsedtime ; cutilSafeCall ( cudaEventElapsedTime ( & elapsedtime , start , stop )); printf ( \"Time to undistort: %3.1f ms \\n \" , elapsedtime ); cutilSafeCall ( cudaEventDestroy ( start )); cutilSafeCall ( cudaEventDestroy ( stop )); //图像的显示及保存 cvNamedWindow ( \"transform\" , 0 ); cvShowImage ( \"transform\" , dst_img ); cvSaveImage ( argv [ 2 ], dst_img , 0 ); cvSaveImage ( \"srcgray.jpeg\" , src_img , 0 ); cvWaitKey ( 0 ); cudaUnbindTexture ( texsrc ); cudaFree ( dst_data ); cudaFreeArray ( srcArray ); cvReleaseImage ( & src_img ); cvReleaseImage ( & dst_img ); return 0 ; } return - 1 ; }","tags":"CUDA","title":"OpenCV+CUDA实现图像变换的小模版"},{"url":"http://www.7rack.info/install-gamit10-4-on-linux-kernel-3.html","text":"今天帮同学在最新的内核3.*.*.*下安装gamit10.4时出错，具体信息如下 OSID Linux 3202 not found in Makefile.config - remove Makefile and STOP 查看gamit/Makefile.config文件会有如下 # ----- for Linux from 0.0.1 to 3.0.0 -- # OS_ID Linux 0001 3000 好的，现在可以将3000修改为 uname -r 的输出中内核的版本 ，我修改后如下 # ----- for Linux from 0.0.1 to 3.0.0 -- # OS_ID Linux 0001 3202 接下来编译就ok了","tags":"Linux","title":"linux kernel 3.*.*.*下安装gamit 10.4"},{"url":"http://www.7rack.info/blackberry-skills.html","text":"测试系统相关部分（包括网络、GPS等）： Options->status: test 显示更多的状态： Options->status: buyr Helpme : Alt + shift + H 显示sms mms phone calls 详细纪录： SMS-- ALT+S MMS-- ALT+M Phonecalls --ALT+P 手机信号的图标换成数字显示: alt+nmll 快速输入手机信息（输入之后按空格键）： Mypin Mynumber myver 自动加入时间：输入 LT 之后按空格键，显示时间; 输入 LD 后按空格键,显示日期. 短信界面快捷键如下: 转到顶部- 按T键(top) 转到底部-按B键(Bottom) 直接回复当前短信-按R键(Reply) 查看已保存短信-按V键 下翻一页-按空格键 上翻一页-cap+空格键 可开启 memory cleaner , password lock 显示黑莓的日志: ALT+LGLG 节省电量: 1.及时退出暂时不需要的应用程序,因为这些程序在后台运行不退出的话,会增加耗电量. 2.设置手机的信号搜索为手动,而不要选择为自动,这样避免手机频频搜索信号耗费电量 3.减少开启屏幕的次数,因为手机的耗电量主要就来源于 这块液晶屏幕. 4.安装电池助推软件,释放电池的隐藏电量,提高电池的使用效率. 5.配置文件,也就是我们习惯说的情景模式,可以通过简单的设置,便捷的更改手机的提醒模式,来适应不同的模式,如 静音模式,振动模式,飞行模式等等. 注：以上均在 9000/5.0.0.1036 上试验.","tags":"Uncategorized","title":"BlackBerry 技巧"},{"url":"http://www.7rack.info/loading-freebsd-with-grub.html","text":"freebsd的安装参考 freebsdchina的wiki ，另外在debian的系统中安装好的grub不能识别freebsd分区，所以需手动添加以引导freebsd。 1.查看分区 $sudo -i # fdisk -l Device Boot Start End Blocks Id System /dev/sda3 * 5167 11785 53163009 5 Extended Partition 3 does not end on cylinder boundary. /dev/sda4 11786 38913 217905660 a5 FreeBSD Partition 4 does not end on cylinder boundary. /dev/sda5 * 5167 6383 9764864 83 Linux /dev/sda6 6383 6886 4041728 82 Linux swap / Solaris /dev/sda7 6886 11785 39354368 83 Linux 注意freebsd分区 # mount -r -t ufs -o ufstype=ufs2 /dev/sda4 /mnt # cat /mnt/etc/fstab # Device Mountpoint FStype Options Dump Pass # /dev/ad4s4b none swap sw 0 0 /dev/ad4s4a / ufs rw 1 1 /dev/ad4s4g /home ufs rw 2 2 /dev/ad4s4e /tmp ufs rw 2 2 /dev/ad4s4f /usr ufs rw 2 2 /dev/ad4s4d /var ufs rw 2 2 /dev/acd0 /cdrom cd9660 ro,noauto 0 0 2.编辑grub.cfg文件 vi /boot/grub/grub.cfg 加入以下内容于40_custom的末尾 常用的方法 menuentry \"FreeBSD 8.3\" { insmod part_msdos insmod ufs2 set root =( hd0,msdos4 ) ＃/boot在哪？ kfreebsd /boot/kernel/kernel kfreebsd_loadenv /boot/device.hints set kFreeBSD.vfs.root.mountfrom = ufs:/dev/ad4s4a set kFreeBSD.vfs.root.mountfrom.options = rw } ` 另一种方法通过chainloader(推荐) menuentry \"FreeBSD 8.3\" { insmod ufs2 set root = '(hd0,msdos4)' chainloader +1 } 然后在freebsd下将 /boot/default/loader.conf 下的delay时间改为-1就可以跳过10秒的等待。 在官方论坛上还有一种方法，不过在我的系统下不能成功 menuentry \"FreeBSD 8.3, boot easy\" { insmod ufs2 set root =( hd0,msdos4,a ) kfreebsd /boot/loader } 参考文章","tags":"FreeBSD","title":"grub引导freebsd"},{"url":"http://www.7rack.info/miss2011.html","text":"下霜了...12.02晨,下午4点多的阳光从楼顶跌落，我还在傻傻的等 今天好失落，突然觉得离自己所说的目标越来越远，又是一次无用的承诺。也许自己真的不配吧,突然觉得好累，想回家了，已经一年没回去。有时候的倔强肯定让人伤心，可是我也不知道为什么会叛逆。大部分的时间我希望是一个人，不喜欢周围总是喧嚣一片...困了,12.17 明天回家，把手机|主机都备份了，带点妈妈喜欢吃的回去之后要有计划，学好cuda和opencv编程，为明年的毕业设计做准备。还要继续学习linux方面的知识在家不要和妈妈顶嘴，不能很倔强。12.27 今天坐火车回家2次都差点没赶上，看来是在学校宅久了，对外面都感觉陌生...看着车上这么多的人，世界好大，有那么几秒钟，我在想我是谁，我在哪里,突然很想念，马上就到考研的时间，希望身边的同学都能实现自己的理想. 12.28","tags":"Uncategorized","title":"季2011"},{"url":"http://www.7rack.info/simple-example-of-opencv.html","text":"一个使用OpenCV库读取 BGR 值，对 BGR 值进行填充的简单例子。 #include \"highgui.h\" #include \"cv.h\" #include <stdio.h> int main ( int arg , char ** argv ) { IplImage * src ; if (( src = cvLoadImage ( argv [ 1 ], - 1 )) != 0 ) //-1可以更改 请查看 说明 { cvNamedWindow ( \"src\" , 1 ); cvShowImage ( \"src\" , src ); cvWaitKey ( 0 ); /*对于多通道单字节型图像*/ int height = src -> height ; int width = src -> width ; int step = src -> widthStep ; int channels = src -> nChannels ; //彩色影像 channels ==3 黑白影像 channels ==1 uchar * data = ( uchar * ) src -> imageData ; int i , j , k ; double a ; /*输出部分RGB值(B、G、R)*/ for ( i = 0 ; i < 50 ; i ++ ) { for ( j = 0 ; j < 50 ; j ++ ) { for ( k = 0 ; k < channels ; k ++ ) { a = data [ i * step + j * channels + k ]; printf ( \"%lf \" , a ); } printf ( \" \\n \" ); } printf ( \" \\n \" ); } /*对左上角区域进行设置*/ for ( i = 0 ; i < 30 ; i ++ ) { for ( j = 0 ; j < 40 ; j ++ ) { for ( k = 0 ; k < channels ; k ++ ) { data [ i * step + j * channels + k ] = 255 ; } } } cvShowImage ( \"src\" , src ); cvWaitKey ( 0 ); cvReleaseImage ( & src ); return 0 ; } return - 1 ; } 编译 gcc -g -Wall -o sample ` pkg-config --libs --cflags opencv ` sample.c 运行 ./sample imL.png","tags":"OpenCV","title":"OpenCV的简单例子(RGB)"},{"url":"http://www.7rack.info/manual-upgrade-firefox.html","text":"最近firefox升级的很快，也出了长期支持版本，而我一直在用的还是ubuntu自带老版本，经常提示可更新，却老是失败。好吧废话不多说。我下载的是10.0.3 长期支持版 先删除老版的火狐，终端中命令如下 sudo apt-get remove firefox 千万不要使用--purge命令，这个会把配置文件也清除的，无法继承以前的配置了。 然后解压firefox到/usr/lib/ 目录 sudo tar xvjf Firefox-latest.tar.bz2 -C /usr/lib/ 下一步就是创建链接到/usr/bin/ sudo ln -s /usr/lib/firefox/firefox /usr/bin/ 最后在终端运行 $ firefox --version Mozilla Firefox 10.0.3 done！第一次运行会检查附件组件的兼容性。","tags":"Linux","title":"firefox手动升级"},{"url":"http://www.7rack.info/install-cuda4-on-ubuntu-win7.html","text":"1. win7 更新显卡驱动；安装CUDA Toolkit和GPU Computing SDK注意记住路径，不必默认。后面提到的NVIDIA GPU Toolkit\\和NVIDIA GPU Computing SDK 4.0\\需根据自己的路径更改为全路径。 所需文件 大致为以下 285.62-notebook-win7-winvista-32bit-international-whql.exe cudatoolkit_4.0.17_win_32.msi cudatools_4.0.17_win_32.msi gpucomputingsdk_4.0.19_win_32.exe CUDA_VS_Wizard_W32.2.2.beta1.zip CUDA VS Wizard一个用于开发CUDA的VS(Visual Studio)向导。当你安装了 CUDA VS Wizard，你将会在你的Visual Studio已安装的模板目录中看到CUDAWinApp。然后很容易就在VS中创建一个新的CUDA项目。 下载 看清32还是64位系统的。 语法高亮 将NVIDIA GPU Computing SDK 4.0\\C\\doc\\syntax_highlighting\\visual_studio_8下的usertype.dat复制到Visua Studio 2008\\Common\\IDE下，并按readme继续设置。 IDE环境设置 启动Visual Studio 2008，选择\"工具\" > \"选项\" > \"项目和解决方案\" > \"C++目录\"，平台选择你的操作系统对应的平台，然后 在\"包含文件\"中添加 NVIDIA GPU Toolkit\\include和NVIDIA GPU Computing SDK 4.0\\C\\common\\inc 在\"库文件\"中添加路径 NVIDIA GPU Toolkit\\lib和NVIDIA GPU Computing SDK 4.0\\C\\common\\lib 在\"源文件\"中添加路径 NVIDIA GPU Toolkit\\src和NVIDIA GPU Computing SDK 4.0\\C\\common\\src 编译规则 的添加 使用CUDA VS Wizard也可手动配置编译规则 创建新的\"Win32控制台应用程序\"后， \"项目\"菜单 > \"自定义生成规则\" > \"查找现有的\" > 找到NVIDIA GPU Computing SDK 4.0\\C\\common下的Cuda.rules > \"确定\" > 勾选找到的编译规则。 \"项目\"菜单 > \"属性\" > \"链接器\" > \"输入\" > \"附加依赖项\"中添加\"cudart.lib cutil32D.lib\"。 打开VS2008\"打开\">\"项目/解决方案\" 找到NVIDIA GPU Computing SDK 4.0\\C\\src\\deviceQuery，并编译 2. ubuntu 所需包在 这里下载 文件如下 cudatoolkit_4.0.17_linux_32_ubuntu10.10.run cudatools_4.0.17_linux_32.run gpucomputingsdk_4.0.17_linux.run 安装完cudatoolkit后 要根据提示，设置有2种方法 gedit ~/.bashrc export PATH=/usr/local/cuda/bin:$PATH export LD_LIBRARY_PATH=/usr/local/cuda/lib:$LD_LIBRARY_PATH 或者 sudo echo \"/usr/local/cuda/lib\" >> /etc/ld.so.conf.d/cuda-40.conf sudo ldconfig 编译GPU Computing SDK code samples cd /usr/local/cuda/NVIDIA_GPU_Computing_SDK make 若出错基本是Library 没装，或者没有链接到正确的库，出错信息如下 /usr/bin/ld: cannot find -lGL collect2: ld returned 1 exit status 基本的库可通过以下命令安装 apt-get install libxi-dev libxmu-dev libglut3-dev 若安装完还是有同样的出错信息，可通过检查相应的.so文件有没有链接上，若没没有 可执行命令 ln -s /usr/lib/nvidia-current/libGL.so /usr/lib/libGL.so 具体可根据错误信息处理 make 完后运行 NVIDIA_GPU_Computing_SDK/C/bin/linux/release# ./deviceQuery [deviceQuery] starting... ./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Found 1 CUDA Capable device(s) Device 0: \"GeForce GT 240M\" CUDA Driver Version / Runtime Version 4.10 / 4.0 CUDA Capability Major/Minor version number: 1.2 Total amount of global memory: 512 MBytes (536543232 bytes) ( 6) Multiprocessors x (8) CUDA Cores/MP: 48 CUDA Cores GPU Clock Speed: 1.21 GHz Memory Clock rate: 810.00 Mhz Memory Bus Width: 128-bit Max Texture Dimension Size (x,y,z) 1D=(8192), 2D=(65536,32768), 3D=(2048,2048,2048) Max Layered Texture Size (dim) x layers 1D=(8192) x 512, 2D=(8192,8192) x 512 Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 16384 bytes Total number of registers available per block: 16384 Warp size: 32 Maximum number of threads per block: 512 Maximum sizes of each dimension of a block: 512 x 512 x 64 Maximum sizes of each dimension of a grid: 65535 x 65535 x 1 Maximum memory pitch: 2147483647 bytes Texture alignment: 256 bytes Concurrent copy and execution: Yes with 1 copy engine(s) Run time limit on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Concurrent kernel execution: No Alignment requirement for Surfaces: Yes Device has ECC support enabled: No Device is using TCC driver mode: No Device supports Unified Addressing (UVA): No Device PCI Bus ID / PCI location ID: 1 / 0 Compute Mode: < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 4.10, CUDA Runtime Version = 4.0, NumDevs = 1, Device = GeForce GT 240M [deviceQuery] test results... PASSED Press ENTER to exit... 建立软链接 mkdir ~/NVIDIA_GPU_Computing_SDK lndir /usr/local/cuda/NVIDIA_GPU_Computing_SDK/ NVIDIA_GPU_Computing_SDK/","tags":"CUDA","title":"配置cuda4.0( ubuntu 10.10 & win7-32)"},{"url":"http://www.7rack.info/filetree-scrip.html","text":"#!/bin/bash #************************************************# # filetree.sh # # edited by 7rack # # December 13, 2011 # # # # This script depends on the tree.sh of # # the Advanced Bash Scripting Guide.Without the # # permission!Just for study:) # #************************************************# #color NORMAL = \"\\033[00m\" # global default, although everything should be something. FILE = \"\\033[00m\" # normal file DIR = \"\\033[01;34m\" # directory LINK = \"\\033[01;36m\" # symbolic link FIFO = \"\\033[40;33m\" # pipe SOCK = \"\\033[01;35m\" # socket EXEC = \"\\033[01;32m\" #execute BLK = \"\\033[40;33;01m\" # block device driver CHR = \"\\033[40;33;01m\" # character device driver ORPHAN = \"\\033[01;05;37;41m\" # orphaned syminks MISSING = \"\\033[01;05;37;41m\" # ... and the files they point to search () { for i in * do zz = 0 # ==> Temp variable, keeping track of directory level. while [ $zz ! = $1 ] # Keep track of inner nested loop. do echo -n \"| \" # ==> Display vertical connector symbol, # ==> with 2 spaces & no line feed in order to indent. zz = ` expr $zz + 1 ` # ==> Increment zz. done if [ -d \" $i \" ] ; then # ==> If it is a directory (-d)... if [ -L \" $i \" ] ; then # ==> If directory is a symbolic link... echo -e \"+-- ${ LINK } $i ${ NORMAL } \" ` ls -l $i | sed 's/&#94;.*' $i ' //' ` # ==> Display horiz. connector and list directory name, but... # ==> delete date/time part of long listing. else echo -e \"+-- ${ DIR } $i ${ NORMAL } \" # ==> Display horizontal connector symbol... # ==> and print directory name. numdirs = ` expr $numdirs + 1 ` # ==> Increment directory count. if cd \" $i \" ; then # ==> If can move to subdirectory... search ` expr $1 + 1 ` # with recursion ;-) # ==> Function calls itself. cd .. fi fi else if [ -L \" $i \" ] ; then #If file is a symbolic link echo -e \"--- ${ LINK } $i ${ NORMAL } \" ` ls -l $i | sed 's/&#94;.*' $i ' //' ` elif [ -p \" $i \" ] ; then #If file is a named pipe echo -e \"--- ${ FIFO } $i ${ NORMAL } \" elif [ -S \" $i \" ] ; then #If file is a socket echo -e \"--- ${ SOCK } $i ${ NORMAL } \" elif [ -x \" $i \" ] ; then #If file's execute (or search) permission is granted echo -e \"--- ${ EXEC } $i ${ NORMAL } \" elif [ -b \" $i \" ] ; then #If file is block special echo -e \"--- ${ BLK } $i ${ NORMAL } \" elif [ -c \" $i \" ] ; then #If file is character special echo -e \"--- ${ CHR } $i ${ NORMAL } \" else echo -e \"--- ${ FILE } $i ${ NORMAL } \" fi (( numfiles+ = 1 )) #Increment file count fi done } if [ $# ! = 0 ] ; then cd $1 # move to indicated directory. #else # stay in current directory fi echo \"Initial directory = `pwd`\" numdirs = 0 numfiles = 0 search 0 echo \"Total directories = $numdirs ,total files = $numfiles \" exit 0 使用示例 $ ./filetree ~/下载 Initial directory = /home/cat/下载 ---aliedit.sh ---install-depot-multisystem.sh +--OS | ---archlinux-2011.08.19-core-x86_64.iso 。。。 Total directories = 6 ,total files = 29 断断续续学了20来天的脚本了，只是有了点基础，还是不会写复杂的程序，keep Going!","tags":"Linux","title":"filetree小脚本"},{"url":"http://www.7rack.info/config-backtrack5.html","text":"基本的配置 安装中文支持（gnome） apt-get install language-selector 安装ubuntu软件中心 apt-get install software-center 没有视频播放软件，在软件中心安装vlc，但是会提示不能以root运行没关系修改个文件就ok vim /usr/bin/vlc 在vi下替换掉个命令 :1,$s/geteuid/getppid/g 配置引导是网上说的kernel /boot/...好像已经变为linux /boot/...,在命令行下显示找不到kernel命令。 显卡驱动和cpyrit-cuda安装 参照 \"更新显卡驱动\" 在配置文件中Device部分找到Driver \"nvidia\"这一行加上 Option \"Coolbits\" \"1\" Option \"NoLogo\" 安装cpyrit-cuda前CUDA-Toolkit，注意$PATH配置.安装前要先安装pyrit，要不有小错误。具体参看 Installation 。 测试下安装情况 pyrit list_cores The following cores seem available... #1: 'CUDA-Device #1 'GeForce 280 GTX'' #2: 'CPU-Core (SSE2)' #/pentest/passwords/crunch/crunch 8 8 123456 | pyrit -i - -e testmomo -o - passthrough | cowpatty -d - -r handshake/testmomo-01.cap -s testmomo ..... ...... 139960 passphrases tested in 74.25 seconds: 1885.01 passphrases/second 偶滴妈呀，cpu百分百，显卡图形库时钟频率最大，温度飙升...心疼了","tags":"Linux","title":"BT 5 r1 配置"},{"url":"http://www.7rack.info/trying-vimrepress.html","text":"从vim官网下载该插件 VimRepress ,我的版本是2.1.5。 具体的安装配置使用参照doc/下的vimpress.txt. 命令有 :BlogList :BlogNew :BlogSave :BlogPreview :BlogOpen :BlogSwitch :BlogUpload :BlogCode 文档里还有tips，说的是Categories和恢复丢失的文档，在写cats栏时，在插入模式下按 Ctrl-x 、 Ctrl-u 就会出现分类。 EditFormat是干嘛的还不晓得:)以后就可以用这个了，强大的插件。","tags":"WordPress","title":"vimRepress 试用"},{"url":"http://www.7rack.info/sysrq-key.html","text":"关于SysRq键介绍详见 开启SysRq键 echo 1 > /proc/sys/kernel/sysrq 配置默认启动magicKey 查看/etc/sysctl.conf，添加 SysRqKey kernel.sysrq = 1 用法 1.\"REISUB\" – safe reboot （busier联想记忆） unRaw 将键盘控制从 X Server 那里抢回来 tErminate 给所有进程发送 SIGTERM 信号，让他们自己解决善后 kIll 给所有进程发送 SIGKILL 信号，强制他们马上关闭 Sync 将所有数据同步至磁盘 Unmount 将所有分区挂载为只读模式 reBoot 重启 时间控制：按e后等待一会儿。 这一切都会直接由 Linux 内核来处理，它可以进行许多低级操作。 笔记本按键不太方便:(Fn+Alt+PrtSc+功能键）,有次没用fn键也行了，下次再测试下","tags":"Linux","title":"SysRq键"},{"url":"http://www.7rack.info/dennis-ritchie.html","text":"丹尼斯•里奇","tags":"Uncategorized","title":"Dennis Ritchie"},{"url":"http://www.7rack.info/config-ip.html","text":"以下是基于ubuntu环境 1.静态IP 编辑/etc/network/interfaces文件like # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). # The loopback network interface auto lo iface lo inet loopback # The primary network interface auto eth0 iface eth0 inet static address 192.168.1.112 netmask 255.255.255.0 network 192.168.1.0 broadcast 192.168.1.255 gateway 192.168.1.1 如果开机启动需再设置下 # update-rc.d networking defaults # /etc/init.d/networking restart 2.通过DHCP获得IP # dhclient eth0","tags":"Linux","title":"ip配置"},{"url":"http://www.7rack.info/cool-cmd-shortcut-key.html","text":"快捷键 Ctrl + a ：移到命令行首 Ctrl + e ：移到命令行尾 Ctrl + f ：按字符前移（右向） Alt + b ：按单词后移（左向） Ctrl + u ：从光标处删除至命令行首 Ctrl + k ：从光标处删除至命令行尾 Ctrl + w ：从光标处删除至字首 Alt + d ：从光标处删除至字尾 Ctrl + r：逆向搜索命令历史 !!：执行上一条命令 Ctrl + z：挂起命令 Ctrl + d: exit cool cmd sudo !! ：以root权限执行上一条命令 :w !sudo tee % ：在 Vim 中无需权限保存编辑的文件 &#94;foo&#94;bar ：将上一条命令中的 foo 替换为 bar，并执行 cp filename { ,.bak } ：快速备份或复制文件","tags":"Linux","title":"命令行加速"},{"url":"http://www.7rack.info/prettify-desktop.html","text":"参考ubuntu forum下的 3D桌面完全教程","tags":"Linux","title":"美化"},{"url":"http://www.7rack.info/show-conky.html","text":"加入了wireless part：) 蛋蛋 好喜欢蛋蛋图，最近有来个..参考ubuntu forum conky配置","tags":"Linux","title":"conky"},{"url":"http://www.7rack.info/time.html","text":"突然地想法，会不会有一种流逝不是以时间来计算呢...也许在另一种\"维\"中我们的\"世界线\"是相交的","tags":"Uncategorized","title":"时光"}]}